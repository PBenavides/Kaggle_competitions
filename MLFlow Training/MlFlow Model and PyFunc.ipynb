{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sirviendo modelos con MLFlow.\n",
    "\n",
    "Un caso rápido con Pytorch e Iris Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = pd.read_csv('https://raw.githubusercontent.com/HackSpacePeru/Datasets_intro_Data_Science/master/Iris_people/iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ¿A qué se le llaman artifacts?\n",
    "\n",
    "Artifacts no son más que objetos útiles e instanciados que usaremos para hacer nuestro proceso de predicción. Por ejemplo, puede ser un modelo ya entrenado, un diccionario que encodee algunas variables categóricas, o el famoso state_dict (los pesos del modelo) de Pytorch. En este caso, es necesario usar un LabelEncoder para poder continuar con el proceso de nuestro modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_encoder = LabelEncoder()\n",
    "L_encoder_path = 'artifacts/label_encoder.pkl'\n",
    "\n",
    "iris['tipo_flor'] = L_encoder.fit_transform(iris['tipo_flor'])\n",
    "\n",
    "#Tenemos que guardar este artifact para la inferecncia posterior.\n",
    "\n",
    "with open(L_encoder_path, 'wb') as handle:\n",
    "    pickle.dump(L_encoder, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora, para entrenar generaremos un X_train y X_test con un random seed de 10.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris.drop('tipo_flor',axis=1),\n",
    "                                                    iris['tipo_flor'], random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como usaremos Pytorch, convertiremos nuestro dataframe a tensores.\n",
    "X_train = torch.from_numpy(X_train.values).float()\n",
    "X_test = torch.from_numpy(X_test.values).float()\n",
    "y_train = torch.from_numpy(Y_train.values).view(1,-1)[0].type(torch.LongTensor)\n",
    "y_test = torch.from_numpy(Y_test.values).view(1,-1)[0].type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dónde armamos el modelo?\n",
    "\n",
    "El modelo va a estar definido en un script aparte llamado modelo.py. Esto nos permitirá importar la clase del modelo, con toda la arquitectura de la red neuronal que hayamos decidido usar. ¿Por qué hacemos esto? Porque es una forma más formal de almacenar nuestro modelo para una posterior puesta en producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelo import ModeloIris\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "\n",
    "model = ModeloIris()\n",
    "#Inicializamos el modelo, seteando las configuraciones:\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr = 0.01)\n",
    "fn_perdida = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 loss: 1.0978232622146606\n",
      "Epoch: 100 loss: 0.05463441461324692\n",
      "Epoch: 200 loss: 0.04953571781516075\n",
      "Epoch: 300 loss: 0.048571936786174774\n",
      "Epoch: 400 loss: 0.04827774688601494\n",
      "Epoch: 500 loss: 0.04734855517745018\n",
      "Epoch: 600 loss: 0.04692305997014046\n",
      "Epoch: 700 loss: 0.04737219586968422\n",
      "Epoch: 800 loss: 0.045976363122463226\n",
      "Epoch: 900 loss: 0.04545168951153755\n"
     ]
    }
   ],
   "source": [
    "#Entrenaremos el modelo.\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train)\n",
    "    loss = fn_perdida(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch} loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pytorch\n",
    "\n",
    "mlflow_pytorch_path = 'models/iris_mlflow_pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'mlflow-env', 'channels': ['defaults', 'conda-forge', 'pytorch'], 'dependencies': ['python=3.8.5', 'pytorch=1.8.1+cpu', 'torchvision=0.9.1+cpu', 'pip', {'pip': ['mlflow', 'cloudpickle==1.6.0']}]}\n"
     ]
    }
   ],
   "source": [
    "#Sacaremos el environment de anaconda que estamos usando:\n",
    "conda_env = mlflow.pytorch.get_default_conda_env()\n",
    "print(conda_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardaremos el modelo\n",
    "mlflow.pytorch.save_model(model, mlflow_pytorch_path, conda_env = conda_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hasta acá ya tenemos nuestro modelo. Lo que falta es poder cargarlo desde los archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "loaded_model = mlflow.pytorch.load_model(mlflow_pytorch_path)\n",
    "\n",
    "#Tomamos un ejemplo para hacer la inferencia.\n",
    "\n",
    "ejemplo = torch.tensor([[3.0, 2.5, 1.8, 0.8]])\n",
    "\n",
    "prediccion = torch.argmax(loaded_model(ejemplo), dim = 1)\n",
    "\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos también el state_dict\n",
    "state_dict_path = 'state_dict.pt'\n",
    "torch.save(model.state_dict(), f'{state_dict_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faltan cargar los artifacts y hacer la clase para poder usarlos en la prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts = {\n",
    "    'state_dict' : state_dict_path,\n",
    "    'label_encoder' : L_encoder_path\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    \n",
    "    #El objeto context es dado por MLFlow, y contiene\n",
    "    #los artifacts especificados arriba.\n",
    "    def load_context(self, context):\n",
    "        import torch\n",
    "        import pickle\n",
    "        from modelo import ModeloIris\n",
    "        \n",
    "        #Inicializamos el modelo y el state_dict\n",
    "        self.model = ModeloIris()\n",
    "        self.model.load_state_dict(torch.load(context.artifacts['state_dict']))\n",
    "        \n",
    "        #Cargamos el label encoder.\n",
    "        with open(context.artifacts['label_encoder'],'rb') as handle:\n",
    "            self.label_encoder = pickle.load(handle)\n",
    "            \n",
    "    def predict(self, context, model_input):\n",
    "        \n",
    "        example = torch.tensor(model_input.values)\n",
    "        pred = torch.argmax(model(example.float()), axis=1)\n",
    "        \n",
    "        #Volvemos a codificar los labels como letras.\n",
    "        pred_labels = self.label_encoder.inverse_transform(pred)\n",
    "        \n",
    "        return pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora ¿Para qué necesitamos esa clase? porque vamos a guardar el modelo con MLFlow y esa clase. Para que cuando podamos cargar denuevo el modelo solo tengamos que poner ese .predict() y obtener la clase ya hecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_env = {\n",
    "    'channels': ['defaults', 'pytorch'],\n",
    "    'dependencies': [\n",
    "      f'python=3.8.5',\n",
    "      {\n",
    "          'pip':[\n",
    "            f'mlflow=={mlflow.__version__}',\n",
    "            f'scikit-learn=={sklearn.__version__}',\n",
    "            f'torch=={torch.__version__}',\n",
    "            'cloudpickle==1.6.0'\n",
    "          ]\n",
    "      }\n",
    "    ],\n",
    "    'name': 'mlflow-env-iris'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_pyfunc_model_path = \"models/iris_model_pyfunc\"\n",
    "\n",
    "#Empaquetamos el modelo completo!\n",
    "mlflow.pyfunc.save_model(path = mlflow_pyfunc_model_path,\n",
    "                        python_model=ModelWrapper(),\n",
    "                        artifacts = artifacts,\n",
    "                        conda_env=conda_env,\n",
    "                        code_path=['modelo.py','meta_data.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(mlflow_pyfunc_model_path)\n",
    "\n",
    "test_ = loaded_model.predict(pd.DataFrame([[5.1,3.5,1.4,.02]]))\n",
    "print(test_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uyADoevEiWGw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "98iEMpHhig34"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ziHZPr0irZn"
   },
   "source": [
    "#### Creamos nuestra clase de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_a2MrbiLiqfG"
   },
   "outputs": [],
   "source": [
    "links_csv = ['https://raw.githubusercontent.com/HackSpacePeru/Datasets_intro_Data_Science/master/train1.csv',\r\n",
    "'https://raw.githubusercontent.com/HackSpacePeru/Datasets_intro_Data_Science/master/train2.csv',\r\n",
    "'https://raw.githubusercontent.com/HackSpacePeru/Datasets_intro_Data_Science/master/train3.csv',\r\n",
    "'https://raw.githubusercontent.com/HackSpacePeru/Datasets_intro_Data_Science/master/train4.csv',]\r\n",
    "\r\n",
    "class MNISTDataset(Dataset):\r\n",
    "  def __init__(self, links_csv, mode='train'):\r\n",
    "    self.mode = mode #\r\n",
    "    list_df = [pd.read_csv(link) for link in links_csv]\r\n",
    "    data = pd.concat(list_df)\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    <---------------------------- Preprocesamiento de Datos -------------------------------------->\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    if self.mode == 'train':\r\n",
    "      self.features = data.drop('label',axis=1).values/255.0\r\n",
    "      self.target = data['label'].values\r\n",
    "      #Reshaping\r\n",
    "      self.target = self.target.reshape((-1,1)) #Dejando q se reeshapee solo\r\n",
    "\r\n",
    "    else:\r\n",
    "      self.features = data.values/255.0\r\n",
    "\r\n",
    "  def __len__(self):\r\n",
    "    return len(self.features)\r\n",
    "\r\n",
    "  def __getitem__(self, idx):\r\n",
    "    if self.mode=='train':\r\n",
    "      feat = torch.Tensor(self.features[idx])\r\n",
    "      oupt = torch.Tensor(self.target[idx])\r\n",
    "\r\n",
    "      return {'features':feat,\r\n",
    "              'target':oupt,}\r\n",
    "      \r\n",
    "    else:\r\n",
    "      feat = torch.Tensor(self.features[idx])\r\n",
    "      return {'features':feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]['features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XcqLFzS7lW72"
   },
   "outputs": [],
   "source": [
    "test_links = ['https://raw.githubusercontent.com/HackSpacePeru/Datasets_intro_Data_Science/master/test.csv']\r\n",
    "\r\n",
    "train = MNISTDataset(links_csv = links_csv, mode='train')\r\n",
    "test = MNISTDataset(links_csv=test_links, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8vfqHtHnpfO3"
   },
   "outputs": [],
   "source": [
    "#Ahora vamos a crear los DataLoades para poder obtener los batchs.\r\n",
    "\r\n",
    "train_loader = DataLoader(train, batch_size=64, shuffle = True)\r\n",
    "test_loader = DataLoader(test, batch_size=64, shuffle =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sELOndA6uSLL"
   },
   "source": [
    "### Modelling MultiLayerPerceptron (MLP)\r\n",
    "\r\n",
    "Vamos a ver que primero haremos una clase heredada de la clase nn.Module, y también usaremos super() para poder heredar los atributos de la clase nn.Module. Así tendremos acceso y más flexibilidad para extender esta clase nn.Module. \r\n",
    "\r\n",
    "#### Definiendo el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "A9j4SPG8m4Yd"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\r\n",
    "\r\n",
    "class MLP(nn.Module):\r\n",
    "  def __init__(self, i, u, v, o):\r\n",
    "    \"\"\"\r\n",
    "    Donde i,u,v,o son los números de neuronas de \r\n",
    "    entrada y salida que tendrá mi red.\r\n",
    "    \"\"\"\r\n",
    "    super(MLP, self).__init__()\r\n",
    "    self.relu_layer = nn.ReLU()\r\n",
    "    self.dense_1 = nn.Linear(i, u)\r\n",
    "    self.b1 = nn.BatchNorm1d(20)\r\n",
    "    self.dense_2 = nn.Linear(u,v)\r\n",
    "    self.dense_output = nn.Linear(v, o)\r\n",
    "\r\n",
    "\r\n",
    "  def forward(self, x):\r\n",
    "    x = self.relu_layer(self.dense_1(x)) # activation( Capa )\r\n",
    "    x = self.b1(x) #Batch Layer\r\n",
    "    x = self.relu_layer(self.dense_2(x)) # Activation(Capa)\r\n",
    "\r\n",
    "    logits = self.dense_output(x)\r\n",
    "\r\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM0ZolwAxzxU"
   },
   "source": [
    "### Inicializando la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (relu_layer): ReLU()\n",
      "  (dense_1): Linear(in_features=784, out_features=20, bias=True)\n",
      "  (b1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dense_2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dense_output): Linear(in_features=20, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "#Usamos el GPU\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "red_neuronal = MLP(i=784, u = 20, v=20, o = 10).to(device) #Acá puedo definir los layers <- Notar nombre de objeto.\n",
    "\n",
    "optimizer = Adam(params=red_neuronal.parameters(), lr=0.01)\n",
    "print(red_neuronal) #Imprimimos la arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "O0I5hBwAyObV"
   },
   "outputs": [],
   "source": [
    "#Definimos nuestra función de pérdida\r\n",
    "\r\n",
    "def accuracy(y_true, y_pred):\r\n",
    "  y_true = y_true.long().squeeze()\r\n",
    "  y_pred = torch.argmax(y_pred, axis=1)\r\n",
    "  return (y_true == y_pred).float().sum()/len(y_true)\r\n",
    "\r\n",
    "def cross_entropy_loss(y_true, y_pred):\r\n",
    "  y_true = y_true.long().squeeze()\r\n",
    "  return nn.CrossEntropyLoss()(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxmuVKtszz3H"
   },
   "source": [
    "### Entrenando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING ...\n",
      "\n",
      "Epoch: 1\n",
      "Batch: 10 || Train Loss: 1.532 || Train Acc: 0.594 || Time: 0.519 s\n",
      "Batch: 20 || Train Loss: 1.017 || Train Acc: 0.703 || Time: 0.848 s\n",
      "Batch: 30 || Train Loss: 0.714 || Train Acc: 0.781 || Time: 1.138 s\n",
      "Batch: 40 || Train Loss: 0.478 || Train Acc: 0.859 || Time: 1.362 s\n",
      "Batch: 50 || Train Loss: 0.529 || Train Acc: 0.828 || Time: 1.602 s\n",
      "Batch: 60 || Train Loss: 0.517 || Train Acc: 0.844 || Time: 1.837 s\n",
      "Batch: 70 || Train Loss: 0.534 || Train Acc: 0.812 || Time: 2.166 s\n",
      "Batch: 80 || Train Loss: 0.225 || Train Acc: 0.922 || Time: 2.359 s\n",
      "Batch: 90 || Train Loss: 0.432 || Train Acc: 0.828 || Time: 2.588 s\n",
      "Batch: 100 || Train Loss: 0.48 || Train Acc: 0.891 || Time: 2.835 s\n",
      "Batch: 110 || Train Loss: 0.542 || Train Acc: 0.891 || Time: 3.121 s\n",
      "Batch: 120 || Train Loss: 0.399 || Train Acc: 0.859 || Time: 3.288 s\n",
      "Batch: 130 || Train Loss: 0.266 || Train Acc: 0.938 || Time: 3.502 s\n",
      "Batch: 140 || Train Loss: 0.318 || Train Acc: 0.922 || Time: 3.687 s\n",
      "Batch: 150 || Train Loss: 0.167 || Train Acc: 0.969 || Time: 3.988 s\n",
      "Batch: 160 || Train Loss: 0.292 || Train Acc: 0.938 || Time: 4.177 s\n",
      "Batch: 170 || Train Loss: 0.374 || Train Acc: 0.844 || Time: 4.405 s\n",
      "Batch: 180 || Train Loss: 0.251 || Train Acc: 0.891 || Time: 4.573 s\n",
      "Batch: 190 || Train Loss: 0.403 || Train Acc: 0.875 || Time: 4.747 s\n",
      "Batch: 200 || Train Loss: 0.258 || Train Acc: 0.938 || Time: 4.906 s\n",
      "Batch: 210 || Train Loss: 0.264 || Train Acc: 0.906 || Time: 5.096 s\n",
      "Batch: 220 || Train Loss: 0.224 || Train Acc: 0.938 || Time: 5.315 s\n",
      "Batch: 230 || Train Loss: 0.411 || Train Acc: 0.891 || Time: 5.518 s\n",
      "Batch: 240 || Train Loss: 0.261 || Train Acc: 0.922 || Time: 5.701 s\n",
      "Batch: 250 || Train Loss: 0.248 || Train Acc: 0.922 || Time: 5.869 s\n",
      "Batch: 260 || Train Loss: 0.348 || Train Acc: 0.906 || Time: 6.035 s\n",
      "Batch: 270 || Train Loss: 0.243 || Train Acc: 0.906 || Time: 6.184 s\n",
      "Batch: 280 || Train Loss: 0.353 || Train Acc: 0.891 || Time: 6.367 s\n",
      "Batch: 290 || Train Loss: 0.133 || Train Acc: 0.953 || Time: 6.571 s\n",
      "Batch: 300 || Train Loss: 0.291 || Train Acc: 0.938 || Time: 6.754 s\n",
      "Batch: 310 || Train Loss: 0.315 || Train Acc: 0.922 || Time: 6.967 s\n",
      "Batch: 320 || Train Loss: 0.163 || Train Acc: 0.953 || Time: 7.097 s\n",
      "Batch: 330 || Train Loss: 0.502 || Train Acc: 0.859 || Time: 7.251 s\n",
      "Batch: 340 || Train Loss: 0.341 || Train Acc: 0.922 || Time: 7.387 s\n",
      "Batch: 350 || Train Loss: 0.346 || Train Acc: 0.922 || Time: 7.555 s\n",
      "Batch: 360 || Train Loss: 0.332 || Train Acc: 0.891 || Time: 7.691 s\n",
      "Batch: 370 || Train Loss: 0.241 || Train Acc: 0.938 || Time: 7.819 s\n",
      "Batch: 380 || Train Loss: 0.251 || Train Acc: 0.906 || Time: 7.962 s\n",
      "Batch: 390 || Train Loss: 0.287 || Train Acc: 0.922 || Time: 8.107 s\n",
      "Batch: 400 || Train Loss: 0.294 || Train Acc: 0.906 || Time: 8.246 s\n",
      "Batch: 410 || Train Loss: 0.419 || Train Acc: 0.922 || Time: 8.392 s\n",
      "Epoch: 2\n",
      "Batch: 10 || Train Loss: 0.377 || Train Acc: 0.906 || Time: 8.557 s\n",
      "Batch: 20 || Train Loss: 0.153 || Train Acc: 0.938 || Time: 8.694 s\n",
      "Batch: 30 || Train Loss: 0.247 || Train Acc: 0.938 || Time: 8.81 s\n",
      "Batch: 40 || Train Loss: 0.443 || Train Acc: 0.844 || Time: 8.969 s\n",
      "Batch: 50 || Train Loss: 0.156 || Train Acc: 0.953 || Time: 9.073 s\n",
      "Batch: 60 || Train Loss: 0.289 || Train Acc: 0.922 || Time: 9.171 s\n",
      "Batch: 70 || Train Loss: 0.409 || Train Acc: 0.906 || Time: 9.29 s\n",
      "Batch: 80 || Train Loss: 0.262 || Train Acc: 0.922 || Time: 9.43 s\n",
      "Batch: 90 || Train Loss: 0.174 || Train Acc: 0.969 || Time: 9.582 s\n",
      "Batch: 100 || Train Loss: 0.162 || Train Acc: 0.922 || Time: 9.684 s\n",
      "Batch: 110 || Train Loss: 0.106 || Train Acc: 0.984 || Time: 9.781 s\n",
      "Batch: 120 || Train Loss: 0.414 || Train Acc: 0.844 || Time: 9.991 s\n",
      "Batch: 130 || Train Loss: 0.228 || Train Acc: 0.938 || Time: 10.076 s\n",
      "Batch: 140 || Train Loss: 0.329 || Train Acc: 0.906 || Time: 10.153 s\n",
      "Batch: 150 || Train Loss: 0.117 || Train Acc: 0.969 || Time: 10.231 s\n",
      "Batch: 160 || Train Loss: 0.199 || Train Acc: 0.953 || Time: 10.311 s\n",
      "Batch: 170 || Train Loss: 0.308 || Train Acc: 0.891 || Time: 10.4 s\n",
      "Batch: 180 || Train Loss: 0.089 || Train Acc: 0.984 || Time: 10.521 s\n",
      "Batch: 190 || Train Loss: 0.296 || Train Acc: 0.891 || Time: 10.62 s\n",
      "Batch: 200 || Train Loss: 0.233 || Train Acc: 0.922 || Time: 10.701 s\n",
      "Batch: 210 || Train Loss: 0.127 || Train Acc: 0.953 || Time: 10.797 s\n",
      "Batch: 220 || Train Loss: 0.118 || Train Acc: 0.969 || Time: 10.887 s\n",
      "Batch: 230 || Train Loss: 0.155 || Train Acc: 0.953 || Time: 10.999 s\n",
      "Batch: 240 || Train Loss: 0.24 || Train Acc: 0.953 || Time: 11.066 s\n",
      "Batch: 250 || Train Loss: 0.398 || Train Acc: 0.906 || Time: 11.14 s\n",
      "Batch: 260 || Train Loss: 0.196 || Train Acc: 0.938 || Time: 11.221 s\n",
      "Batch: 270 || Train Loss: 0.181 || Train Acc: 0.906 || Time: 11.3 s\n",
      "Batch: 280 || Train Loss: 0.195 || Train Acc: 0.953 || Time: 11.384 s\n",
      "Batch: 290 || Train Loss: 0.187 || Train Acc: 0.953 || Time: 11.453 s\n",
      "Batch: 300 || Train Loss: 0.076 || Train Acc: 0.984 || Time: 11.531 s\n",
      "Batch: 310 || Train Loss: 0.132 || Train Acc: 0.953 || Time: 11.641 s\n",
      "Batch: 320 || Train Loss: 0.145 || Train Acc: 0.953 || Time: 11.734 s\n",
      "Batch: 330 || Train Loss: 0.21 || Train Acc: 0.906 || Time: 11.813 s\n",
      "Batch: 340 || Train Loss: 0.343 || Train Acc: 0.922 || Time: 11.888 s\n",
      "Batch: 350 || Train Loss: 0.158 || Train Acc: 0.969 || Time: 11.982 s\n",
      "Batch: 360 || Train Loss: 0.148 || Train Acc: 0.938 || Time: 12.06 s\n",
      "Batch: 370 || Train Loss: 0.158 || Train Acc: 0.938 || Time: 12.152 s\n",
      "Batch: 380 || Train Loss: 0.101 || Train Acc: 0.953 || Time: 12.227 s\n",
      "Batch: 390 || Train Loss: 0.188 || Train Acc: 0.922 || Time: 12.291 s\n",
      "Batch: 400 || Train Loss: 0.249 || Train Acc: 0.922 || Time: 12.374 s\n",
      "Batch: 410 || Train Loss: 0.209 || Train Acc: 0.922 || Time: 12.478 s\n",
      "Epoch: 3\n",
      "Batch: 10 || Train Loss: 0.126 || Train Acc: 0.938 || Time: 12.583 s\n",
      "Batch: 20 || Train Loss: 0.193 || Train Acc: 0.953 || Time: 12.658 s\n",
      "Batch: 30 || Train Loss: 0.06 || Train Acc: 0.984 || Time: 12.713 s\n",
      "Batch: 40 || Train Loss: 0.081 || Train Acc: 0.969 || Time: 12.785 s\n",
      "Batch: 50 || Train Loss: 0.218 || Train Acc: 0.922 || Time: 12.886 s\n",
      "Batch: 60 || Train Loss: 0.083 || Train Acc: 0.969 || Time: 12.992 s\n",
      "Batch: 70 || Train Loss: 0.123 || Train Acc: 0.953 || Time: 13.074 s\n",
      "Batch: 80 || Train Loss: 0.086 || Train Acc: 0.969 || Time: 13.144 s\n",
      "Batch: 90 || Train Loss: 0.189 || Train Acc: 0.953 || Time: 13.216 s\n",
      "Batch: 100 || Train Loss: 0.172 || Train Acc: 0.922 || Time: 13.302 s\n",
      "Batch: 110 || Train Loss: 0.11 || Train Acc: 0.953 || Time: 13.389 s\n",
      "Batch: 120 || Train Loss: 0.301 || Train Acc: 0.906 || Time: 13.465 s\n",
      "Batch: 130 || Train Loss: 0.118 || Train Acc: 0.969 || Time: 13.534 s\n",
      "Batch: 140 || Train Loss: 0.141 || Train Acc: 0.938 || Time: 13.593 s\n",
      "Batch: 150 || Train Loss: 0.151 || Train Acc: 0.953 || Time: 13.675 s\n",
      "Batch: 160 || Train Loss: 0.244 || Train Acc: 0.953 || Time: 13.786 s\n",
      "Batch: 170 || Train Loss: 0.133 || Train Acc: 0.953 || Time: 13.887 s\n",
      "Batch: 180 || Train Loss: 0.104 || Train Acc: 0.953 || Time: 13.987 s\n",
      "Batch: 190 || Train Loss: 0.231 || Train Acc: 0.922 || Time: 14.058 s\n",
      "Batch: 200 || Train Loss: 0.108 || Train Acc: 0.953 || Time: 14.149 s\n",
      "Batch: 210 || Train Loss: 0.117 || Train Acc: 0.953 || Time: 14.228 s\n",
      "Batch: 220 || Train Loss: 0.162 || Train Acc: 0.953 || Time: 14.303 s\n",
      "Batch: 230 || Train Loss: 0.178 || Train Acc: 0.938 || Time: 14.398 s\n",
      "Batch: 240 || Train Loss: 0.121 || Train Acc: 0.938 || Time: 14.482 s\n",
      "Batch: 250 || Train Loss: 0.162 || Train Acc: 0.953 || Time: 14.558 s\n",
      "Batch: 260 || Train Loss: 0.164 || Train Acc: 0.938 || Time: 14.647 s\n",
      "Batch: 270 || Train Loss: 0.046 || Train Acc: 0.984 || Time: 14.727 s\n",
      "Batch: 280 || Train Loss: 0.159 || Train Acc: 0.969 || Time: 14.811 s\n",
      "Batch: 290 || Train Loss: 0.11 || Train Acc: 0.938 || Time: 14.902 s\n",
      "Batch: 300 || Train Loss: 0.043 || Train Acc: 1.0 || Time: 14.994 s\n",
      "Batch: 310 || Train Loss: 0.108 || Train Acc: 0.984 || Time: 15.084 s\n",
      "Batch: 320 || Train Loss: 0.239 || Train Acc: 0.938 || Time: 15.17 s\n",
      "Batch: 330 || Train Loss: 0.23 || Train Acc: 0.922 || Time: 15.232 s\n",
      "Batch: 340 || Train Loss: 0.228 || Train Acc: 0.969 || Time: 15.315 s\n",
      "Batch: 350 || Train Loss: 0.228 || Train Acc: 0.922 || Time: 15.402 s\n",
      "Batch: 360 || Train Loss: 0.246 || Train Acc: 0.938 || Time: 15.475 s\n",
      "Batch: 370 || Train Loss: 0.18 || Train Acc: 0.922 || Time: 15.531 s\n",
      "Batch: 380 || Train Loss: 0.203 || Train Acc: 0.938 || Time: 15.602 s\n",
      "Batch: 390 || Train Loss: 0.079 || Train Acc: 0.969 || Time: 15.698 s\n",
      "Batch: 400 || Train Loss: 0.096 || Train Acc: 0.953 || Time: 15.777 s\n",
      "Batch: 410 || Train Loss: 0.226 || Train Acc: 0.938 || Time: 15.855 s\n",
      "Epoch: 4\n",
      "Batch: 10 || Train Loss: 0.073 || Train Acc: 0.984 || Time: 15.999 s\n",
      "Batch: 20 || Train Loss: 0.085 || Train Acc: 0.969 || Time: 16.08 s\n",
      "Batch: 30 || Train Loss: 0.249 || Train Acc: 0.938 || Time: 16.144 s\n",
      "Batch: 40 || Train Loss: 0.157 || Train Acc: 0.938 || Time: 16.214 s\n",
      "Batch: 50 || Train Loss: 0.154 || Train Acc: 0.938 || Time: 16.299 s\n",
      "Batch: 60 || Train Loss: 0.075 || Train Acc: 0.984 || Time: 16.379 s\n",
      "Batch: 70 || Train Loss: 0.076 || Train Acc: 0.969 || Time: 16.444 s\n",
      "Batch: 80 || Train Loss: 0.27 || Train Acc: 0.953 || Time: 16.513 s\n",
      "Batch: 90 || Train Loss: 0.103 || Train Acc: 0.969 || Time: 16.587 s\n",
      "Batch: 100 || Train Loss: 0.196 || Train Acc: 0.953 || Time: 16.681 s\n",
      "Batch: 110 || Train Loss: 0.186 || Train Acc: 0.938 || Time: 16.763 s\n",
      "Batch: 120 || Train Loss: 0.313 || Train Acc: 0.891 || Time: 16.828 s\n",
      "Batch: 130 || Train Loss: 0.194 || Train Acc: 0.922 || Time: 16.93 s\n",
      "Batch: 140 || Train Loss: 0.205 || Train Acc: 0.922 || Time: 17.022 s\n",
      "Batch: 150 || Train Loss: 0.19 || Train Acc: 0.953 || Time: 17.093 s\n",
      "Batch: 160 || Train Loss: 0.049 || Train Acc: 0.984 || Time: 17.161 s\n",
      "Batch: 170 || Train Loss: 0.089 || Train Acc: 0.984 || Time: 17.241 s\n",
      "Batch: 180 || Train Loss: 0.291 || Train Acc: 0.938 || Time: 17.316 s\n",
      "Batch: 190 || Train Loss: 0.248 || Train Acc: 0.938 || Time: 17.411 s\n",
      "Batch: 200 || Train Loss: 0.101 || Train Acc: 0.969 || Time: 17.469 s\n",
      "Batch: 210 || Train Loss: 0.201 || Train Acc: 0.953 || Time: 17.534 s\n",
      "Batch: 220 || Train Loss: 0.355 || Train Acc: 0.859 || Time: 17.612 s\n",
      "Batch: 230 || Train Loss: 0.133 || Train Acc: 0.953 || Time: 17.709 s\n",
      "Batch: 240 || Train Loss: 0.14 || Train Acc: 0.969 || Time: 17.771 s\n",
      "Batch: 250 || Train Loss: 0.093 || Train Acc: 0.969 || Time: 17.83 s\n",
      "Batch: 260 || Train Loss: 0.348 || Train Acc: 0.891 || Time: 17.916 s\n",
      "Batch: 270 || Train Loss: 0.149 || Train Acc: 0.953 || Time: 17.987 s\n",
      "Batch: 280 || Train Loss: 0.113 || Train Acc: 0.938 || Time: 18.048 s\n",
      "Batch: 290 || Train Loss: 0.19 || Train Acc: 0.922 || Time: 18.123 s\n",
      "Batch: 300 || Train Loss: 0.087 || Train Acc: 0.969 || Time: 18.278 s\n",
      "Batch: 310 || Train Loss: 0.105 || Train Acc: 0.969 || Time: 18.385 s\n",
      "Batch: 320 || Train Loss: 0.233 || Train Acc: 0.953 || Time: 18.447 s\n",
      "Batch: 330 || Train Loss: 0.167 || Train Acc: 0.953 || Time: 18.518 s\n",
      "Batch: 340 || Train Loss: 0.155 || Train Acc: 0.922 || Time: 18.59 s\n",
      "Batch: 350 || Train Loss: 0.05 || Train Acc: 1.0 || Time: 18.661 s\n",
      "Batch: 360 || Train Loss: 0.183 || Train Acc: 0.938 || Time: 18.742 s\n",
      "Batch: 370 || Train Loss: 0.069 || Train Acc: 0.953 || Time: 18.828 s\n",
      "Batch: 380 || Train Loss: 0.101 || Train Acc: 0.953 || Time: 18.937 s\n",
      "Batch: 390 || Train Loss: 0.195 || Train Acc: 0.938 || Time: 19.035 s\n",
      "Batch: 400 || Train Loss: 0.1 || Train Acc: 0.969 || Time: 19.112 s\n",
      "Batch: 410 || Train Loss: 0.22 || Train Acc: 0.953 || Time: 19.209 s\n",
      "Epoch: 5\n",
      "Batch: 10 || Train Loss: 0.214 || Train Acc: 0.969 || Time: 19.317 s\n",
      "Batch: 20 || Train Loss: 0.141 || Train Acc: 0.953 || Time: 19.41 s\n",
      "Batch: 30 || Train Loss: 0.102 || Train Acc: 0.953 || Time: 19.51 s\n",
      "Batch: 40 || Train Loss: 0.059 || Train Acc: 0.984 || Time: 19.58 s\n",
      "Batch: 50 || Train Loss: 0.232 || Train Acc: 0.969 || Time: 19.667 s\n",
      "Batch: 60 || Train Loss: 0.164 || Train Acc: 0.938 || Time: 19.766 s\n",
      "Batch: 70 || Train Loss: 0.301 || Train Acc: 0.922 || Time: 19.893 s\n",
      "Batch: 80 || Train Loss: 0.161 || Train Acc: 0.969 || Time: 19.999 s\n",
      "Batch: 90 || Train Loss: 0.281 || Train Acc: 0.922 || Time: 20.07 s\n",
      "Batch: 100 || Train Loss: 0.128 || Train Acc: 0.953 || Time: 20.148 s\n",
      "Batch: 110 || Train Loss: 0.111 || Train Acc: 0.953 || Time: 20.239 s\n",
      "Batch: 120 || Train Loss: 0.087 || Train Acc: 0.953 || Time: 20.358 s\n",
      "Batch: 130 || Train Loss: 0.062 || Train Acc: 1.0 || Time: 20.474 s\n",
      "Batch: 140 || Train Loss: 0.111 || Train Acc: 0.938 || Time: 20.556 s\n",
      "Batch: 150 || Train Loss: 0.161 || Train Acc: 0.969 || Time: 20.653 s\n",
      "Batch: 160 || Train Loss: 0.122 || Train Acc: 0.969 || Time: 20.736 s\n",
      "Batch: 170 || Train Loss: 0.063 || Train Acc: 0.969 || Time: 20.825 s\n",
      "Batch: 180 || Train Loss: 0.084 || Train Acc: 0.969 || Time: 20.935 s\n",
      "Batch: 190 || Train Loss: 0.097 || Train Acc: 0.953 || Time: 21.03 s\n",
      "Batch: 200 || Train Loss: 0.226 || Train Acc: 0.906 || Time: 21.089 s\n",
      "Batch: 210 || Train Loss: 0.251 || Train Acc: 0.938 || Time: 21.165 s\n",
      "Batch: 220 || Train Loss: 0.185 || Train Acc: 0.938 || Time: 21.26 s\n",
      "Batch: 230 || Train Loss: 0.16 || Train Acc: 0.938 || Time: 21.326 s\n",
      "Batch: 240 || Train Loss: 0.156 || Train Acc: 0.953 || Time: 21.409 s\n",
      "Batch: 250 || Train Loss: 0.25 || Train Acc: 0.953 || Time: 21.479 s\n",
      "Batch: 260 || Train Loss: 0.071 || Train Acc: 0.969 || Time: 21.544 s\n",
      "Batch: 270 || Train Loss: 0.069 || Train Acc: 0.984 || Time: 21.61 s\n",
      "Batch: 280 || Train Loss: 0.052 || Train Acc: 0.984 || Time: 21.691 s\n",
      "Batch: 290 || Train Loss: 0.087 || Train Acc: 0.969 || Time: 21.77 s\n",
      "Batch: 300 || Train Loss: 0.109 || Train Acc: 0.969 || Time: 21.847 s\n",
      "Batch: 310 || Train Loss: 0.116 || Train Acc: 0.969 || Time: 21.958 s\n",
      "Batch: 320 || Train Loss: 0.104 || Train Acc: 0.953 || Time: 22.037 s\n",
      "Batch: 330 || Train Loss: 0.172 || Train Acc: 0.938 || Time: 22.126 s\n",
      "Batch: 340 || Train Loss: 0.064 || Train Acc: 0.969 || Time: 22.198 s\n",
      "Batch: 350 || Train Loss: 0.124 || Train Acc: 0.969 || Time: 22.262 s\n",
      "Batch: 360 || Train Loss: 0.1 || Train Acc: 0.969 || Time: 22.336 s\n",
      "Batch: 370 || Train Loss: 0.059 || Train Acc: 0.969 || Time: 22.399 s\n",
      "Batch: 380 || Train Loss: 0.193 || Train Acc: 0.922 || Time: 22.464 s\n",
      "Batch: 390 || Train Loss: 0.089 || Train Acc: 0.969 || Time: 22.54 s\n",
      "Batch: 400 || Train Loss: 0.143 || Train Acc: 0.922 || Time: 22.601 s\n",
      "Batch: 410 || Train Loss: 0.247 || Train Acc: 0.938 || Time: 22.662 s\n",
      "Epoch: 6\n",
      "Batch: 10 || Train Loss: 0.137 || Train Acc: 0.984 || Time: 22.771 s\n",
      "Batch: 20 || Train Loss: 0.281 || Train Acc: 0.906 || Time: 22.826 s\n",
      "Batch: 30 || Train Loss: 0.13 || Train Acc: 0.953 || Time: 22.907 s\n",
      "Batch: 40 || Train Loss: 0.079 || Train Acc: 0.969 || Time: 23.011 s\n",
      "Batch: 50 || Train Loss: 0.24 || Train Acc: 0.938 || Time: 23.092 s\n",
      "Batch: 60 || Train Loss: 0.13 || Train Acc: 0.953 || Time: 23.179 s\n",
      "Batch: 70 || Train Loss: 0.234 || Train Acc: 0.953 || Time: 23.258 s\n",
      "Batch: 80 || Train Loss: 0.269 || Train Acc: 0.953 || Time: 23.326 s\n",
      "Batch: 90 || Train Loss: 0.094 || Train Acc: 0.969 || Time: 23.402 s\n",
      "Batch: 100 || Train Loss: 0.049 || Train Acc: 0.984 || Time: 23.488 s\n",
      "Batch: 110 || Train Loss: 0.134 || Train Acc: 0.922 || Time: 23.57 s\n",
      "Batch: 120 || Train Loss: 0.116 || Train Acc: 0.969 || Time: 23.64 s\n",
      "Batch: 130 || Train Loss: 0.252 || Train Acc: 0.922 || Time: 23.722 s\n",
      "Batch: 140 || Train Loss: 0.122 || Train Acc: 0.969 || Time: 23.784 s\n",
      "Batch: 150 || Train Loss: 0.115 || Train Acc: 0.969 || Time: 23.858 s\n",
      "Batch: 160 || Train Loss: 0.164 || Train Acc: 0.953 || Time: 23.961 s\n",
      "Batch: 170 || Train Loss: 0.111 || Train Acc: 0.953 || Time: 24.026 s\n",
      "Batch: 180 || Train Loss: 0.097 || Train Acc: 0.969 || Time: 24.089 s\n",
      "Batch: 190 || Train Loss: 0.14 || Train Acc: 0.922 || Time: 24.147 s\n",
      "Batch: 200 || Train Loss: 0.181 || Train Acc: 0.953 || Time: 24.209 s\n",
      "Batch: 210 || Train Loss: 0.192 || Train Acc: 0.953 || Time: 24.284 s\n",
      "Batch: 220 || Train Loss: 0.049 || Train Acc: 0.984 || Time: 24.351 s\n",
      "Batch: 230 || Train Loss: 0.142 || Train Acc: 0.969 || Time: 24.423 s\n",
      "Batch: 240 || Train Loss: 0.063 || Train Acc: 1.0 || Time: 24.523 s\n",
      "Batch: 250 || Train Loss: 0.161 || Train Acc: 0.922 || Time: 24.623 s\n",
      "Batch: 260 || Train Loss: 0.067 || Train Acc: 0.984 || Time: 24.723 s\n",
      "Batch: 270 || Train Loss: 0.107 || Train Acc: 0.969 || Time: 24.806 s\n",
      "Batch: 280 || Train Loss: 0.49 || Train Acc: 0.906 || Time: 24.878 s\n",
      "Batch: 290 || Train Loss: 0.111 || Train Acc: 0.969 || Time: 24.98 s\n",
      "Batch: 300 || Train Loss: 0.087 || Train Acc: 0.953 || Time: 25.06 s\n",
      "Batch: 310 || Train Loss: 0.367 || Train Acc: 0.906 || Time: 25.143 s\n",
      "Batch: 320 || Train Loss: 0.173 || Train Acc: 0.953 || Time: 25.212 s\n",
      "Batch: 330 || Train Loss: 0.216 || Train Acc: 0.953 || Time: 25.278 s\n",
      "Batch: 340 || Train Loss: 0.05 || Train Acc: 0.969 || Time: 25.35 s\n",
      "Batch: 350 || Train Loss: 0.051 || Train Acc: 0.969 || Time: 25.592 s\n",
      "Batch: 360 || Train Loss: 0.294 || Train Acc: 0.875 || Time: 25.671 s\n",
      "Batch: 370 || Train Loss: 0.395 || Train Acc: 0.922 || Time: 25.75 s\n",
      "Batch: 380 || Train Loss: 0.022 || Train Acc: 1.0 || Time: 25.821 s\n",
      "Batch: 390 || Train Loss: 0.043 || Train Acc: 0.984 || Time: 25.885 s\n",
      "Batch: 400 || Train Loss: 0.473 || Train Acc: 0.875 || Time: 25.993 s\n",
      "Batch: 410 || Train Loss: 0.196 || Train Acc: 0.953 || Time: 26.077 s\n",
      "Epoch: 7\n",
      "Batch: 10 || Train Loss: 0.065 || Train Acc: 0.969 || Time: 26.191 s\n",
      "Batch: 20 || Train Loss: 0.031 || Train Acc: 0.984 || Time: 26.274 s\n",
      "Batch: 30 || Train Loss: 0.051 || Train Acc: 0.984 || Time: 26.342 s\n",
      "Batch: 40 || Train Loss: 0.112 || Train Acc: 0.984 || Time: 26.541 s\n",
      "Batch: 50 || Train Loss: 0.133 || Train Acc: 0.938 || Time: 26.611 s\n",
      "Batch: 60 || Train Loss: 0.108 || Train Acc: 0.969 || Time: 26.678 s\n",
      "Batch: 70 || Train Loss: 0.042 || Train Acc: 1.0 || Time: 26.76 s\n",
      "Batch: 80 || Train Loss: 0.036 || Train Acc: 1.0 || Time: 26.829 s\n",
      "Batch: 90 || Train Loss: 0.025 || Train Acc: 1.0 || Time: 26.891 s\n",
      "Batch: 100 || Train Loss: 0.082 || Train Acc: 0.969 || Time: 26.992 s\n",
      "Batch: 110 || Train Loss: 0.063 || Train Acc: 0.969 || Time: 27.068 s\n",
      "Batch: 120 || Train Loss: 0.137 || Train Acc: 0.953 || Time: 27.143 s\n",
      "Batch: 130 || Train Loss: 0.017 || Train Acc: 1.0 || Time: 27.203 s\n",
      "Batch: 140 || Train Loss: 0.152 || Train Acc: 0.984 || Time: 27.271 s\n",
      "Batch: 150 || Train Loss: 0.043 || Train Acc: 0.984 || Time: 27.329 s\n",
      "Batch: 160 || Train Loss: 0.132 || Train Acc: 0.969 || Time: 27.401 s\n",
      "Batch: 170 || Train Loss: 0.082 || Train Acc: 0.969 || Time: 27.478 s\n",
      "Batch: 180 || Train Loss: 0.189 || Train Acc: 0.953 || Time: 27.553 s\n",
      "Batch: 190 || Train Loss: 0.15 || Train Acc: 0.984 || Time: 27.634 s\n",
      "Batch: 200 || Train Loss: 0.131 || Train Acc: 0.969 || Time: 27.733 s\n",
      "Batch: 210 || Train Loss: 0.259 || Train Acc: 0.922 || Time: 27.806 s\n",
      "Batch: 220 || Train Loss: 0.095 || Train Acc: 0.984 || Time: 27.868 s\n",
      "Batch: 230 || Train Loss: 0.105 || Train Acc: 0.953 || Time: 27.951 s\n",
      "Batch: 240 || Train Loss: 0.038 || Train Acc: 0.984 || Time: 28.012 s\n",
      "Batch: 250 || Train Loss: 0.324 || Train Acc: 0.938 || Time: 28.083 s\n",
      "Batch: 260 || Train Loss: 0.207 || Train Acc: 0.938 || Time: 28.159 s\n",
      "Batch: 270 || Train Loss: 0.2 || Train Acc: 0.906 || Time: 28.236 s\n",
      "Batch: 280 || Train Loss: 0.097 || Train Acc: 0.953 || Time: 28.305 s\n",
      "Batch: 290 || Train Loss: 0.184 || Train Acc: 0.953 || Time: 28.385 s\n",
      "Batch: 300 || Train Loss: 0.19 || Train Acc: 0.906 || Time: 28.467 s\n",
      "Batch: 310 || Train Loss: 0.094 || Train Acc: 0.969 || Time: 28.551 s\n",
      "Batch: 320 || Train Loss: 0.146 || Train Acc: 0.969 || Time: 28.615 s\n",
      "Batch: 330 || Train Loss: 0.165 || Train Acc: 0.938 || Time: 28.68 s\n",
      "Batch: 340 || Train Loss: 0.086 || Train Acc: 0.938 || Time: 28.769 s\n",
      "Batch: 350 || Train Loss: 0.165 || Train Acc: 0.938 || Time: 28.851 s\n",
      "Batch: 360 || Train Loss: 0.095 || Train Acc: 0.953 || Time: 28.947 s\n",
      "Batch: 370 || Train Loss: 0.106 || Train Acc: 0.969 || Time: 29.009 s\n",
      "Batch: 380 || Train Loss: 0.255 || Train Acc: 0.891 || Time: 29.078 s\n",
      "Batch: 390 || Train Loss: 0.127 || Train Acc: 0.969 || Time: 29.138 s\n",
      "Batch: 400 || Train Loss: 0.226 || Train Acc: 0.938 || Time: 29.197 s\n",
      "Batch: 410 || Train Loss: 0.043 || Train Acc: 0.984 || Time: 29.266 s\n",
      "Epoch: 8\n",
      "Batch: 10 || Train Loss: 0.029 || Train Acc: 1.0 || Time: 29.373 s\n",
      "Batch: 20 || Train Loss: 0.141 || Train Acc: 0.984 || Time: 29.454 s\n",
      "Batch: 30 || Train Loss: 0.134 || Train Acc: 0.984 || Time: 29.512 s\n",
      "Batch: 40 || Train Loss: 0.075 || Train Acc: 0.938 || Time: 29.589 s\n",
      "Batch: 50 || Train Loss: 0.108 || Train Acc: 0.984 || Time: 29.651 s\n",
      "Batch: 60 || Train Loss: 0.094 || Train Acc: 0.969 || Time: 29.718 s\n",
      "Batch: 70 || Train Loss: 0.102 || Train Acc: 0.969 || Time: 29.786 s\n",
      "Batch: 80 || Train Loss: 0.081 || Train Acc: 0.969 || Time: 29.853 s\n",
      "Batch: 90 || Train Loss: 0.087 || Train Acc: 0.984 || Time: 29.973 s\n",
      "Batch: 100 || Train Loss: 0.072 || Train Acc: 0.984 || Time: 30.035 s\n",
      "Batch: 110 || Train Loss: 0.185 || Train Acc: 0.969 || Time: 30.107 s\n",
      "Batch: 120 || Train Loss: 0.386 || Train Acc: 0.906 || Time: 30.162 s\n",
      "Batch: 130 || Train Loss: 0.132 || Train Acc: 0.953 || Time: 30.229 s\n",
      "Batch: 140 || Train Loss: 0.077 || Train Acc: 0.969 || Time: 30.29 s\n",
      "Batch: 150 || Train Loss: 0.075 || Train Acc: 0.969 || Time: 30.365 s\n",
      "Batch: 160 || Train Loss: 0.268 || Train Acc: 0.906 || Time: 30.43 s\n",
      "Batch: 170 || Train Loss: 0.03 || Train Acc: 1.0 || Time: 30.501 s\n",
      "Batch: 180 || Train Loss: 0.093 || Train Acc: 0.969 || Time: 30.582 s\n",
      "Batch: 190 || Train Loss: 0.084 || Train Acc: 0.969 || Time: 30.651 s\n",
      "Batch: 200 || Train Loss: 0.217 || Train Acc: 0.938 || Time: 30.709 s\n",
      "Batch: 210 || Train Loss: 0.044 || Train Acc: 1.0 || Time: 30.772 s\n",
      "Batch: 220 || Train Loss: 0.271 || Train Acc: 0.953 || Time: 30.834 s\n",
      "Batch: 230 || Train Loss: 0.125 || Train Acc: 0.969 || Time: 30.907 s\n",
      "Batch: 240 || Train Loss: 0.215 || Train Acc: 0.922 || Time: 30.987 s\n",
      "Batch: 250 || Train Loss: 0.012 || Train Acc: 1.0 || Time: 31.053 s\n",
      "Batch: 260 || Train Loss: 0.265 || Train Acc: 0.922 || Time: 31.153 s\n",
      "Batch: 270 || Train Loss: 0.226 || Train Acc: 0.969 || Time: 31.228 s\n",
      "Batch: 280 || Train Loss: 0.232 || Train Acc: 0.906 || Time: 31.284 s\n",
      "Batch: 290 || Train Loss: 0.178 || Train Acc: 0.969 || Time: 31.359 s\n",
      "Batch: 300 || Train Loss: 0.14 || Train Acc: 0.938 || Time: 31.446 s\n",
      "Batch: 310 || Train Loss: 0.149 || Train Acc: 0.953 || Time: 31.528 s\n",
      "Batch: 320 || Train Loss: 0.168 || Train Acc: 0.953 || Time: 31.622 s\n",
      "Batch: 330 || Train Loss: 0.194 || Train Acc: 0.938 || Time: 31.691 s\n",
      "Batch: 340 || Train Loss: 0.11 || Train Acc: 0.953 || Time: 31.775 s\n",
      "Batch: 350 || Train Loss: 0.137 || Train Acc: 0.938 || Time: 31.859 s\n",
      "Batch: 360 || Train Loss: 0.028 || Train Acc: 1.0 || Time: 31.97 s\n",
      "Batch: 370 || Train Loss: 0.065 || Train Acc: 0.969 || Time: 32.053 s\n",
      "Batch: 380 || Train Loss: 0.092 || Train Acc: 0.953 || Time: 32.132 s\n",
      "Batch: 390 || Train Loss: 0.138 || Train Acc: 0.953 || Time: 32.192 s\n",
      "Batch: 400 || Train Loss: 0.295 || Train Acc: 0.922 || Time: 32.261 s\n",
      "Batch: 410 || Train Loss: 0.12 || Train Acc: 0.969 || Time: 32.358 s\n",
      "Epoch: 9\n",
      "Batch: 10 || Train Loss: 0.115 || Train Acc: 0.922 || Time: 32.484 s\n",
      "Batch: 20 || Train Loss: 0.035 || Train Acc: 0.984 || Time: 32.548 s\n",
      "Batch: 30 || Train Loss: 0.095 || Train Acc: 0.969 || Time: 32.637 s\n",
      "Batch: 40 || Train Loss: 0.128 || Train Acc: 0.969 || Time: 32.732 s\n",
      "Batch: 50 || Train Loss: 0.06 || Train Acc: 0.984 || Time: 32.816 s\n",
      "Batch: 60 || Train Loss: 0.098 || Train Acc: 0.953 || Time: 32.919 s\n",
      "Batch: 70 || Train Loss: 0.103 || Train Acc: 0.938 || Time: 32.986 s\n",
      "Batch: 80 || Train Loss: 0.03 || Train Acc: 1.0 || Time: 33.051 s\n",
      "Batch: 90 || Train Loss: 0.184 || Train Acc: 0.922 || Time: 33.115 s\n",
      "Batch: 100 || Train Loss: 0.071 || Train Acc: 0.969 || Time: 33.191 s\n",
      "Batch: 110 || Train Loss: 0.083 || Train Acc: 0.969 || Time: 33.258 s\n",
      "Batch: 120 || Train Loss: 0.066 || Train Acc: 0.969 || Time: 33.33 s\n",
      "Batch: 130 || Train Loss: 0.031 || Train Acc: 1.0 || Time: 33.411 s\n",
      "Batch: 140 || Train Loss: 0.058 || Train Acc: 1.0 || Time: 33.506 s\n",
      "Batch: 150 || Train Loss: 0.053 || Train Acc: 0.984 || Time: 33.592 s\n",
      "Batch: 160 || Train Loss: 0.062 || Train Acc: 0.984 || Time: 33.681 s\n",
      "Batch: 170 || Train Loss: 0.106 || Train Acc: 0.969 || Time: 33.755 s\n",
      "Batch: 180 || Train Loss: 0.127 || Train Acc: 0.969 || Time: 33.836 s\n",
      "Batch: 190 || Train Loss: 0.172 || Train Acc: 0.938 || Time: 33.931 s\n",
      "Batch: 200 || Train Loss: 0.063 || Train Acc: 1.0 || Time: 34.003 s\n",
      "Batch: 210 || Train Loss: 0.246 || Train Acc: 0.906 || Time: 34.081 s\n",
      "Batch: 220 || Train Loss: 0.074 || Train Acc: 0.969 || Time: 34.162 s\n",
      "Batch: 230 || Train Loss: 0.13 || Train Acc: 0.938 || Time: 34.241 s\n",
      "Batch: 240 || Train Loss: 0.105 || Train Acc: 0.969 || Time: 34.319 s\n",
      "Batch: 250 || Train Loss: 0.029 || Train Acc: 0.984 || Time: 34.401 s\n",
      "Batch: 260 || Train Loss: 0.151 || Train Acc: 0.953 || Time: 34.466 s\n",
      "Batch: 270 || Train Loss: 0.045 || Train Acc: 0.984 || Time: 34.541 s\n",
      "Batch: 280 || Train Loss: 0.041 || Train Acc: 0.969 || Time: 34.607 s\n",
      "Batch: 290 || Train Loss: 0.156 || Train Acc: 0.922 || Time: 34.678 s\n",
      "Batch: 300 || Train Loss: 0.121 || Train Acc: 0.953 || Time: 34.768 s\n",
      "Batch: 310 || Train Loss: 0.107 || Train Acc: 0.969 || Time: 34.846 s\n",
      "Batch: 320 || Train Loss: 0.131 || Train Acc: 0.938 || Time: 34.935 s\n",
      "Batch: 330 || Train Loss: 0.035 || Train Acc: 1.0 || Time: 35.002 s\n",
      "Batch: 340 || Train Loss: 0.105 || Train Acc: 0.969 || Time: 35.063 s\n",
      "Batch: 350 || Train Loss: 0.191 || Train Acc: 0.969 || Time: 35.139 s\n",
      "Batch: 360 || Train Loss: 0.087 || Train Acc: 0.953 || Time: 35.212 s\n",
      "Batch: 370 || Train Loss: 0.046 || Train Acc: 0.969 || Time: 35.279 s\n",
      "Batch: 380 || Train Loss: 0.024 || Train Acc: 1.0 || Time: 35.344 s\n",
      "Batch: 390 || Train Loss: 0.114 || Train Acc: 0.953 || Time: 35.406 s\n",
      "Batch: 400 || Train Loss: 0.082 || Train Acc: 0.953 || Time: 35.466 s\n",
      "Batch: 410 || Train Loss: 0.104 || Train Acc: 0.938 || Time: 35.524 s\n",
      "Epoch: 10\n",
      "Batch: 10 || Train Loss: 0.12 || Train Acc: 0.938 || Time: 35.605 s\n",
      "Batch: 20 || Train Loss: 0.053 || Train Acc: 0.953 || Time: 35.676 s\n",
      "Batch: 30 || Train Loss: 0.107 || Train Acc: 0.938 || Time: 35.734 s\n",
      "Batch: 40 || Train Loss: 0.057 || Train Acc: 0.984 || Time: 35.805 s\n",
      "Batch: 50 || Train Loss: 0.058 || Train Acc: 0.969 || Time: 35.892 s\n",
      "Batch: 60 || Train Loss: 0.038 || Train Acc: 0.984 || Time: 36.028 s\n",
      "Batch: 70 || Train Loss: 0.187 || Train Acc: 0.969 || Time: 36.09 s\n",
      "Batch: 80 || Train Loss: 0.048 || Train Acc: 1.0 || Time: 36.155 s\n",
      "Batch: 90 || Train Loss: 0.235 || Train Acc: 0.922 || Time: 36.22 s\n",
      "Batch: 100 || Train Loss: 0.154 || Train Acc: 0.969 || Time: 36.28 s\n",
      "Batch: 110 || Train Loss: 0.079 || Train Acc: 0.984 || Time: 36.342 s\n",
      "Batch: 120 || Train Loss: 0.162 || Train Acc: 0.953 || Time: 36.413 s\n",
      "Batch: 130 || Train Loss: 0.14 || Train Acc: 0.938 || Time: 36.494 s\n",
      "Batch: 140 || Train Loss: 0.135 || Train Acc: 0.969 || Time: 36.76 s\n",
      "Batch: 150 || Train Loss: 0.16 || Train Acc: 0.938 || Time: 37.186 s\n",
      "Batch: 160 || Train Loss: 0.03 || Train Acc: 0.984 || Time: 38.266 s\n",
      "Batch: 170 || Train Loss: 0.099 || Train Acc: 0.969 || Time: 38.811 s\n",
      "Batch: 180 || Train Loss: 0.142 || Train Acc: 0.969 || Time: 39.185 s\n",
      "Batch: 190 || Train Loss: 0.032 || Train Acc: 1.0 || Time: 39.742 s\n",
      "Batch: 200 || Train Loss: 0.035 || Train Acc: 0.984 || Time: 40.27 s\n",
      "Batch: 210 || Train Loss: 0.11 || Train Acc: 0.969 || Time: 40.608 s\n",
      "Batch: 220 || Train Loss: 0.298 || Train Acc: 0.922 || Time: 41.017 s\n",
      "Batch: 230 || Train Loss: 0.176 || Train Acc: 0.938 || Time: 41.167 s\n",
      "Batch: 240 || Train Loss: 0.055 || Train Acc: 0.984 || Time: 41.282 s\n",
      "Batch: 250 || Train Loss: 0.084 || Train Acc: 0.969 || Time: 41.41 s\n",
      "Batch: 260 || Train Loss: 0.141 || Train Acc: 0.922 || Time: 41.551 s\n",
      "Batch: 270 || Train Loss: 0.131 || Train Acc: 0.984 || Time: 41.689 s\n",
      "Batch: 280 || Train Loss: 0.115 || Train Acc: 0.984 || Time: 41.828 s\n",
      "Batch: 290 || Train Loss: 0.038 || Train Acc: 1.0 || Time: 41.962 s\n",
      "Batch: 300 || Train Loss: 0.124 || Train Acc: 0.969 || Time: 42.044 s\n",
      "Batch: 310 || Train Loss: 0.04 || Train Acc: 1.0 || Time: 42.143 s\n",
      "Batch: 320 || Train Loss: 0.036 || Train Acc: 0.984 || Time: 42.282 s\n",
      "Batch: 330 || Train Loss: 0.104 || Train Acc: 0.969 || Time: 42.37 s\n",
      "Batch: 340 || Train Loss: 0.108 || Train Acc: 0.984 || Time: 42.472 s\n",
      "Batch: 350 || Train Loss: 0.044 || Train Acc: 0.984 || Time: 42.581 s\n",
      "Batch: 360 || Train Loss: 0.015 || Train Acc: 1.0 || Time: 42.665 s\n",
      "Batch: 370 || Train Loss: 0.096 || Train Acc: 0.969 || Time: 42.77 s\n",
      "Batch: 380 || Train Loss: 0.052 || Train Acc: 0.984 || Time: 42.868 s\n",
      "Batch: 390 || Train Loss: 0.112 || Train Acc: 0.984 || Time: 42.986 s\n",
      "Batch: 400 || Train Loss: 0.09 || Train Acc: 0.953 || Time: 43.069 s\n",
      "Batch: 410 || Train Loss: 0.225 || Train Acc: 0.953 || Time: 43.161 s\n",
      "Epoch: 11\n",
      "Batch: 10 || Train Loss: 0.068 || Train Acc: 0.969 || Time: 43.318 s\n",
      "Batch: 20 || Train Loss: 0.086 || Train Acc: 0.969 || Time: 43.43 s\n",
      "Batch: 30 || Train Loss: 0.181 || Train Acc: 0.953 || Time: 43.55 s\n",
      "Batch: 40 || Train Loss: 0.063 || Train Acc: 0.969 || Time: 43.673 s\n",
      "Batch: 50 || Train Loss: 0.106 || Train Acc: 0.969 || Time: 43.778 s\n",
      "Batch: 60 || Train Loss: 0.02 || Train Acc: 1.0 || Time: 43.878 s\n",
      "Batch: 70 || Train Loss: 0.055 || Train Acc: 0.984 || Time: 43.981 s\n",
      "Batch: 80 || Train Loss: 0.031 || Train Acc: 1.0 || Time: 44.09 s\n",
      "Batch: 90 || Train Loss: 0.052 || Train Acc: 0.984 || Time: 44.183 s\n",
      "Batch: 100 || Train Loss: 0.085 || Train Acc: 0.969 || Time: 44.267 s\n",
      "Batch: 110 || Train Loss: 0.106 || Train Acc: 0.984 || Time: 44.336 s\n",
      "Batch: 120 || Train Loss: 0.189 || Train Acc: 0.922 || Time: 44.434 s\n",
      "Batch: 130 || Train Loss: 0.105 || Train Acc: 0.969 || Time: 44.526 s\n",
      "Batch: 140 || Train Loss: 0.113 || Train Acc: 0.969 || Time: 44.614 s\n",
      "Batch: 150 || Train Loss: 0.059 || Train Acc: 0.984 || Time: 44.698 s\n",
      "Batch: 160 || Train Loss: 0.21 || Train Acc: 0.938 || Time: 44.784 s\n",
      "Batch: 170 || Train Loss: 0.118 || Train Acc: 0.984 || Time: 44.875 s\n",
      "Batch: 180 || Train Loss: 0.108 || Train Acc: 0.953 || Time: 44.961 s\n",
      "Batch: 190 || Train Loss: 0.033 || Train Acc: 0.984 || Time: 45.027 s\n",
      "Batch: 200 || Train Loss: 0.587 || Train Acc: 0.891 || Time: 45.086 s\n",
      "Batch: 210 || Train Loss: 0.183 || Train Acc: 0.938 || Time: 45.166 s\n",
      "Batch: 220 || Train Loss: 0.218 || Train Acc: 0.953 || Time: 45.268 s\n",
      "Batch: 230 || Train Loss: 0.024 || Train Acc: 1.0 || Time: 45.349 s\n",
      "Batch: 240 || Train Loss: 0.054 || Train Acc: 0.984 || Time: 45.503 s\n",
      "Batch: 250 || Train Loss: 0.417 || Train Acc: 0.906 || Time: 45.566 s\n",
      "Batch: 260 || Train Loss: 0.141 || Train Acc: 0.969 || Time: 45.636 s\n",
      "Batch: 270 || Train Loss: 0.095 || Train Acc: 0.953 || Time: 45.696 s\n",
      "Batch: 280 || Train Loss: 0.062 || Train Acc: 0.984 || Time: 45.766 s\n",
      "Batch: 290 || Train Loss: 0.022 || Train Acc: 1.0 || Time: 45.838 s\n",
      "Batch: 300 || Train Loss: 0.115 || Train Acc: 0.953 || Time: 45.906 s\n",
      "Batch: 310 || Train Loss: 0.16 || Train Acc: 0.969 || Time: 46.01 s\n",
      "Batch: 320 || Train Loss: 0.151 || Train Acc: 0.969 || Time: 46.077 s\n",
      "Batch: 330 || Train Loss: 0.15 || Train Acc: 0.953 || Time: 46.137 s\n",
      "Batch: 340 || Train Loss: 0.095 || Train Acc: 0.984 || Time: 46.201 s\n",
      "Batch: 350 || Train Loss: 0.071 || Train Acc: 0.953 || Time: 46.271 s\n",
      "Batch: 360 || Train Loss: 0.12 || Train Acc: 0.938 || Time: 46.34 s\n",
      "Batch: 370 || Train Loss: 0.108 || Train Acc: 0.922 || Time: 46.406 s\n",
      "Batch: 380 || Train Loss: 0.084 || Train Acc: 0.969 || Time: 46.465 s\n",
      "Batch: 390 || Train Loss: 0.111 || Train Acc: 0.938 || Time: 46.535 s\n",
      "Batch: 400 || Train Loss: 0.057 || Train Acc: 0.969 || Time: 46.622 s\n",
      "Batch: 410 || Train Loss: 0.074 || Train Acc: 0.969 || Time: 46.682 s\n",
      "Epoch: 12\n",
      "Batch: 10 || Train Loss: 0.108 || Train Acc: 0.969 || Time: 46.78 s\n",
      "Batch: 20 || Train Loss: 0.027 || Train Acc: 1.0 || Time: 46.852 s\n",
      "Batch: 30 || Train Loss: 0.039 || Train Acc: 0.984 || Time: 46.936 s\n",
      "Batch: 40 || Train Loss: 0.029 || Train Acc: 0.984 || Time: 47.022 s\n",
      "Batch: 50 || Train Loss: 0.081 || Train Acc: 0.969 || Time: 47.087 s\n",
      "Batch: 60 || Train Loss: 0.028 || Train Acc: 1.0 || Time: 47.159 s\n",
      "Batch: 70 || Train Loss: 0.173 || Train Acc: 0.938 || Time: 47.225 s\n",
      "Batch: 80 || Train Loss: 0.154 || Train Acc: 0.984 || Time: 47.284 s\n",
      "Batch: 90 || Train Loss: 0.031 || Train Acc: 0.984 || Time: 47.355 s\n",
      "Batch: 100 || Train Loss: 0.04 || Train Acc: 0.984 || Time: 47.417 s\n",
      "Batch: 110 || Train Loss: 0.028 || Train Acc: 1.0 || Time: 47.475 s\n",
      "Batch: 120 || Train Loss: 0.091 || Train Acc: 0.953 || Time: 47.538 s\n",
      "Batch: 130 || Train Loss: 0.177 || Train Acc: 0.938 || Time: 47.604 s\n",
      "Batch: 140 || Train Loss: 0.019 || Train Acc: 1.0 || Time: 47.679 s\n",
      "Batch: 150 || Train Loss: 0.017 || Train Acc: 1.0 || Time: 47.747 s\n",
      "Batch: 160 || Train Loss: 0.053 || Train Acc: 0.984 || Time: 47.813 s\n",
      "Batch: 170 || Train Loss: 0.219 || Train Acc: 0.922 || Time: 47.873 s\n",
      "Batch: 180 || Train Loss: 0.037 || Train Acc: 0.984 || Time: 47.962 s\n",
      "Batch: 190 || Train Loss: 0.036 || Train Acc: 0.984 || Time: 48.03 s\n",
      "Batch: 200 || Train Loss: 0.043 || Train Acc: 1.0 || Time: 48.09 s\n",
      "Batch: 210 || Train Loss: 0.22 || Train Acc: 0.938 || Time: 48.152 s\n",
      "Batch: 220 || Train Loss: 0.161 || Train Acc: 0.953 || Time: 48.236 s\n",
      "Batch: 230 || Train Loss: 0.031 || Train Acc: 1.0 || Time: 48.3 s\n",
      "Batch: 240 || Train Loss: 0.123 || Train Acc: 0.922 || Time: 48.379 s\n",
      "Batch: 250 || Train Loss: 0.121 || Train Acc: 0.969 || Time: 48.453 s\n",
      "Batch: 260 || Train Loss: 0.055 || Train Acc: 0.969 || Time: 48.515 s\n",
      "Batch: 270 || Train Loss: 0.152 || Train Acc: 0.938 || Time: 48.568 s\n",
      "Batch: 280 || Train Loss: 0.033 || Train Acc: 0.984 || Time: 48.634 s\n",
      "Batch: 290 || Train Loss: 0.082 || Train Acc: 0.969 || Time: 48.718 s\n",
      "Batch: 300 || Train Loss: 0.042 || Train Acc: 0.984 || Time: 48.791 s\n",
      "Batch: 310 || Train Loss: 0.127 || Train Acc: 0.938 || Time: 48.874 s\n",
      "Batch: 320 || Train Loss: 0.057 || Train Acc: 0.984 || Time: 48.993 s\n",
      "Batch: 330 || Train Loss: 0.134 || Train Acc: 0.969 || Time: 49.057 s\n",
      "Batch: 340 || Train Loss: 0.062 || Train Acc: 0.984 || Time: 49.135 s\n",
      "Batch: 350 || Train Loss: 0.243 || Train Acc: 0.922 || Time: 49.222 s\n",
      "Batch: 360 || Train Loss: 0.041 || Train Acc: 0.984 || Time: 49.296 s\n",
      "Batch: 370 || Train Loss: 0.061 || Train Acc: 0.984 || Time: 49.382 s\n",
      "Batch: 380 || Train Loss: 0.079 || Train Acc: 0.984 || Time: 49.463 s\n",
      "Batch: 390 || Train Loss: 0.124 || Train Acc: 0.953 || Time: 49.53 s\n",
      "Batch: 400 || Train Loss: 0.148 || Train Acc: 0.938 || Time: 49.624 s\n",
      "Batch: 410 || Train Loss: 0.108 || Train Acc: 0.953 || Time: 49.725 s\n",
      "Epoch: 13\n",
      "Batch: 10 || Train Loss: 0.087 || Train Acc: 0.984 || Time: 49.84 s\n",
      "Batch: 20 || Train Loss: 0.11 || Train Acc: 0.969 || Time: 49.935 s\n",
      "Batch: 30 || Train Loss: 0.049 || Train Acc: 0.984 || Time: 50.007 s\n",
      "Batch: 40 || Train Loss: 0.111 || Train Acc: 0.953 || Time: 50.066 s\n",
      "Batch: 50 || Train Loss: 0.015 || Train Acc: 1.0 || Time: 50.143 s\n",
      "Batch: 60 || Train Loss: 0.043 || Train Acc: 1.0 || Time: 50.229 s\n",
      "Batch: 70 || Train Loss: 0.035 || Train Acc: 1.0 || Time: 50.311 s\n",
      "Batch: 80 || Train Loss: 0.005 || Train Acc: 1.0 || Time: 50.381 s\n",
      "Batch: 90 || Train Loss: 0.028 || Train Acc: 1.0 || Time: 50.443 s\n",
      "Batch: 100 || Train Loss: 0.103 || Train Acc: 0.953 || Time: 50.519 s\n",
      "Batch: 110 || Train Loss: 0.07 || Train Acc: 0.984 || Time: 50.6 s\n",
      "Batch: 120 || Train Loss: 0.129 || Train Acc: 0.969 || Time: 50.667 s\n",
      "Batch: 130 || Train Loss: 0.062 || Train Acc: 0.984 || Time: 50.749 s\n",
      "Batch: 140 || Train Loss: 0.086 || Train Acc: 0.984 || Time: 50.815 s\n",
      "Batch: 150 || Train Loss: 0.034 || Train Acc: 0.984 || Time: 50.885 s\n",
      "Batch: 160 || Train Loss: 0.031 || Train Acc: 0.984 || Time: 51.007 s\n",
      "Batch: 170 || Train Loss: 0.048 || Train Acc: 0.969 || Time: 51.079 s\n",
      "Batch: 180 || Train Loss: 0.086 || Train Acc: 0.969 || Time: 51.155 s\n",
      "Batch: 190 || Train Loss: 0.155 || Train Acc: 0.969 || Time: 51.221 s\n",
      "Batch: 200 || Train Loss: 0.218 || Train Acc: 0.953 || Time: 51.287 s\n",
      "Batch: 210 || Train Loss: 0.048 || Train Acc: 0.984 || Time: 51.347 s\n",
      "Batch: 220 || Train Loss: 0.078 || Train Acc: 0.969 || Time: 51.407 s\n",
      "Batch: 230 || Train Loss: 0.098 || Train Acc: 0.969 || Time: 51.469 s\n",
      "Batch: 240 || Train Loss: 0.116 || Train Acc: 0.969 || Time: 51.528 s\n",
      "Batch: 250 || Train Loss: 0.077 || Train Acc: 0.969 || Time: 51.606 s\n",
      "Batch: 260 || Train Loss: 0.14 || Train Acc: 0.953 || Time: 51.68 s\n",
      "Batch: 270 || Train Loss: 0.256 || Train Acc: 0.953 || Time: 51.738 s\n",
      "Batch: 280 || Train Loss: 0.064 || Train Acc: 0.984 || Time: 51.816 s\n",
      "Batch: 290 || Train Loss: 0.107 || Train Acc: 0.953 || Time: 51.899 s\n",
      "Batch: 300 || Train Loss: 0.1 || Train Acc: 0.953 || Time: 51.987 s\n",
      "Batch: 310 || Train Loss: 0.125 || Train Acc: 0.953 || Time: 52.063 s\n",
      "Batch: 320 || Train Loss: 0.099 || Train Acc: 0.969 || Time: 52.128 s\n",
      "Batch: 330 || Train Loss: 0.232 || Train Acc: 0.953 || Time: 52.195 s\n",
      "Batch: 340 || Train Loss: 0.036 || Train Acc: 0.984 || Time: 52.257 s\n",
      "Batch: 350 || Train Loss: 0.133 || Train Acc: 0.969 || Time: 52.453 s\n",
      "Batch: 360 || Train Loss: 0.225 || Train Acc: 0.922 || Time: 52.753 s\n",
      "Batch: 370 || Train Loss: 0.035 || Train Acc: 0.984 || Time: 53.001 s\n",
      "Batch: 380 || Train Loss: 0.093 || Train Acc: 0.969 || Time: 53.209 s\n",
      "Batch: 390 || Train Loss: 0.114 || Train Acc: 0.984 || Time: 53.465 s\n",
      "Batch: 400 || Train Loss: 0.075 || Train Acc: 0.984 || Time: 53.691 s\n",
      "Batch: 410 || Train Loss: 0.075 || Train Acc: 0.984 || Time: 53.878 s\n",
      "Epoch: 14\n",
      "Batch: 10 || Train Loss: 0.158 || Train Acc: 0.938 || Time: 54.184 s\n",
      "Batch: 20 || Train Loss: 0.036 || Train Acc: 0.984 || Time: 54.396 s\n",
      "Batch: 30 || Train Loss: 0.051 || Train Acc: 0.984 || Time: 54.617 s\n",
      "Batch: 40 || Train Loss: 0.219 || Train Acc: 0.922 || Time: 54.804 s\n",
      "Batch: 50 || Train Loss: 0.085 || Train Acc: 0.953 || Time: 55.012 s\n",
      "Batch: 60 || Train Loss: 0.194 || Train Acc: 0.969 || Time: 55.171 s\n",
      "Batch: 70 || Train Loss: 0.154 || Train Acc: 0.969 || Time: 55.417 s\n",
      "Batch: 80 || Train Loss: 0.182 || Train Acc: 0.953 || Time: 55.894 s\n",
      "Batch: 90 || Train Loss: 0.015 || Train Acc: 1.0 || Time: 56.347 s\n",
      "Batch: 100 || Train Loss: 0.005 || Train Acc: 1.0 || Time: 56.712 s\n",
      "Batch: 110 || Train Loss: 0.179 || Train Acc: 0.906 || Time: 57.044 s\n",
      "Batch: 120 || Train Loss: 0.065 || Train Acc: 0.969 || Time: 57.21 s\n",
      "Batch: 130 || Train Loss: 0.012 || Train Acc: 1.0 || Time: 57.333 s\n",
      "Batch: 140 || Train Loss: 0.013 || Train Acc: 1.0 || Time: 57.454 s\n",
      "Batch: 150 || Train Loss: 0.111 || Train Acc: 0.953 || Time: 57.629 s\n",
      "Batch: 160 || Train Loss: 0.046 || Train Acc: 0.984 || Time: 57.756 s\n",
      "Batch: 170 || Train Loss: 0.041 || Train Acc: 0.984 || Time: 57.932 s\n",
      "Batch: 180 || Train Loss: 0.13 || Train Acc: 0.938 || Time: 58.063 s\n",
      "Batch: 190 || Train Loss: 0.057 || Train Acc: 0.984 || Time: 58.16 s\n",
      "Batch: 200 || Train Loss: 0.227 || Train Acc: 0.922 || Time: 58.265 s\n",
      "Batch: 210 || Train Loss: 0.053 || Train Acc: 0.984 || Time: 58.431 s\n",
      "Batch: 220 || Train Loss: 0.087 || Train Acc: 0.953 || Time: 58.529 s\n",
      "Batch: 230 || Train Loss: 0.037 || Train Acc: 0.984 || Time: 58.665 s\n",
      "Batch: 240 || Train Loss: 0.141 || Train Acc: 0.938 || Time: 58.788 s\n",
      "Batch: 250 || Train Loss: 0.112 || Train Acc: 0.953 || Time: 58.99 s\n",
      "Batch: 260 || Train Loss: 0.085 || Train Acc: 0.969 || Time: 59.116 s\n",
      "Batch: 270 || Train Loss: 0.124 || Train Acc: 0.969 || Time: 59.228 s\n",
      "Batch: 280 || Train Loss: 0.341 || Train Acc: 0.922 || Time: 59.363 s\n",
      "Batch: 290 || Train Loss: 0.154 || Train Acc: 0.969 || Time: 59.5 s\n",
      "Batch: 300 || Train Loss: 0.033 || Train Acc: 1.0 || Time: 59.646 s\n",
      "Batch: 310 || Train Loss: 0.136 || Train Acc: 0.969 || Time: 59.764 s\n",
      "Batch: 320 || Train Loss: 0.111 || Train Acc: 0.969 || Time: 59.883 s\n",
      "Batch: 330 || Train Loss: 0.056 || Train Acc: 0.953 || Time: 60.003 s\n",
      "Batch: 340 || Train Loss: 0.045 || Train Acc: 1.0 || Time: 60.11 s\n",
      "Batch: 350 || Train Loss: 0.208 || Train Acc: 0.922 || Time: 60.22 s\n",
      "Batch: 360 || Train Loss: 0.167 || Train Acc: 0.938 || Time: 60.324 s\n",
      "Batch: 370 || Train Loss: 0.031 || Train Acc: 1.0 || Time: 60.428 s\n",
      "Batch: 380 || Train Loss: 0.138 || Train Acc: 0.938 || Time: 60.517 s\n",
      "Batch: 390 || Train Loss: 0.177 || Train Acc: 0.953 || Time: 60.65 s\n",
      "Batch: 400 || Train Loss: 0.13 || Train Acc: 0.969 || Time: 60.767 s\n",
      "Batch: 410 || Train Loss: 0.095 || Train Acc: 0.969 || Time: 60.868 s\n",
      "Epoch: 15\n",
      "Batch: 10 || Train Loss: 0.026 || Train Acc: 1.0 || Time: 61.101 s\n",
      "Batch: 20 || Train Loss: 0.044 || Train Acc: 1.0 || Time: 61.248 s\n",
      "Batch: 30 || Train Loss: 0.027 || Train Acc: 0.984 || Time: 61.357 s\n",
      "Batch: 40 || Train Loss: 0.018 || Train Acc: 1.0 || Time: 61.457 s\n",
      "Batch: 50 || Train Loss: 0.294 || Train Acc: 0.906 || Time: 61.544 s\n",
      "Batch: 60 || Train Loss: 0.044 || Train Acc: 0.984 || Time: 61.643 s\n",
      "Batch: 70 || Train Loss: 0.07 || Train Acc: 0.984 || Time: 61.748 s\n",
      "Batch: 80 || Train Loss: 0.106 || Train Acc: 0.953 || Time: 61.839 s\n",
      "Batch: 90 || Train Loss: 0.006 || Train Acc: 1.0 || Time: 61.973 s\n",
      "Batch: 100 || Train Loss: 0.079 || Train Acc: 0.953 || Time: 62.076 s\n",
      "Batch: 110 || Train Loss: 0.144 || Train Acc: 0.953 || Time: 62.152 s\n",
      "Batch: 120 || Train Loss: 0.032 || Train Acc: 0.984 || Time: 62.255 s\n",
      "Batch: 130 || Train Loss: 0.134 || Train Acc: 0.938 || Time: 62.329 s\n",
      "Batch: 140 || Train Loss: 0.142 || Train Acc: 0.938 || Time: 62.422 s\n",
      "Batch: 150 || Train Loss: 0.083 || Train Acc: 0.984 || Time: 62.503 s\n",
      "Batch: 160 || Train Loss: 0.031 || Train Acc: 1.0 || Time: 62.58 s\n",
      "Batch: 170 || Train Loss: 0.033 || Train Acc: 0.984 || Time: 62.687 s\n",
      "Batch: 180 || Train Loss: 0.238 || Train Acc: 0.953 || Time: 62.779 s\n",
      "Batch: 190 || Train Loss: 0.041 || Train Acc: 0.984 || Time: 62.867 s\n",
      "Batch: 200 || Train Loss: 0.034 || Train Acc: 0.984 || Time: 62.997 s\n",
      "Batch: 210 || Train Loss: 0.033 || Train Acc: 1.0 || Time: 63.087 s\n",
      "Batch: 220 || Train Loss: 0.033 || Train Acc: 1.0 || Time: 63.156 s\n",
      "Batch: 230 || Train Loss: 0.023 || Train Acc: 1.0 || Time: 63.247 s\n",
      "Batch: 240 || Train Loss: 0.084 || Train Acc: 0.969 || Time: 63.313 s\n",
      "Batch: 250 || Train Loss: 0.061 || Train Acc: 0.969 || Time: 63.383 s\n",
      "Batch: 260 || Train Loss: 0.032 || Train Acc: 1.0 || Time: 63.452 s\n",
      "Batch: 270 || Train Loss: 0.038 || Train Acc: 0.984 || Time: 63.528 s\n",
      "Batch: 280 || Train Loss: 0.017 || Train Acc: 1.0 || Time: 63.603 s\n",
      "Batch: 290 || Train Loss: 0.164 || Train Acc: 0.969 || Time: 63.681 s\n",
      "Batch: 300 || Train Loss: 0.049 || Train Acc: 0.984 || Time: 63.75 s\n",
      "Batch: 310 || Train Loss: 0.13 || Train Acc: 0.969 || Time: 63.817 s\n",
      "Batch: 320 || Train Loss: 0.1 || Train Acc: 0.984 || Time: 63.898 s\n",
      "Batch: 330 || Train Loss: 0.053 || Train Acc: 0.969 || Time: 63.983 s\n",
      "Batch: 340 || Train Loss: 0.126 || Train Acc: 0.953 || Time: 64.058 s\n",
      "Batch: 350 || Train Loss: 0.1 || Train Acc: 0.953 || Time: 64.137 s\n",
      "Batch: 360 || Train Loss: 0.118 || Train Acc: 0.969 || Time: 64.233 s\n",
      "Batch: 370 || Train Loss: 0.336 || Train Acc: 0.922 || Time: 64.323 s\n",
      "Batch: 380 || Train Loss: 0.122 || Train Acc: 0.984 || Time: 64.415 s\n",
      "Batch: 390 || Train Loss: 0.043 || Train Acc: 0.984 || Time: 64.485 s\n",
      "Batch: 400 || Train Loss: 0.074 || Train Acc: 0.969 || Time: 64.57 s\n",
      "Batch: 410 || Train Loss: 0.155 || Train Acc: 0.969 || Time: 64.674 s\n",
      "Epoch: 16\n",
      "Batch: 10 || Train Loss: 0.2 || Train Acc: 0.938 || Time: 64.793 s\n",
      "Batch: 20 || Train Loss: 0.059 || Train Acc: 0.984 || Time: 64.853 s\n",
      "Batch: 30 || Train Loss: 0.056 || Train Acc: 0.969 || Time: 64.955 s\n",
      "Batch: 40 || Train Loss: 0.147 || Train Acc: 0.953 || Time: 65.025 s\n",
      "Batch: 50 || Train Loss: 0.076 || Train Acc: 0.953 || Time: 65.085 s\n",
      "Batch: 60 || Train Loss: 0.176 || Train Acc: 0.938 || Time: 65.15 s\n",
      "Batch: 70 || Train Loss: 0.126 || Train Acc: 0.953 || Time: 65.214 s\n",
      "Batch: 80 || Train Loss: 0.062 || Train Acc: 0.969 || Time: 65.294 s\n",
      "Batch: 90 || Train Loss: 0.069 || Train Acc: 0.969 || Time: 65.38 s\n",
      "Batch: 100 || Train Loss: 0.04 || Train Acc: 0.984 || Time: 65.453 s\n",
      "Batch: 110 || Train Loss: 0.041 || Train Acc: 1.0 || Time: 65.523 s\n",
      "Batch: 120 || Train Loss: 0.081 || Train Acc: 0.953 || Time: 65.591 s\n",
      "Batch: 130 || Train Loss: 0.097 || Train Acc: 0.953 || Time: 65.651 s\n",
      "Batch: 140 || Train Loss: 0.016 || Train Acc: 0.984 || Time: 65.734 s\n",
      "Batch: 150 || Train Loss: 0.183 || Train Acc: 0.969 || Time: 65.816 s\n",
      "Batch: 160 || Train Loss: 0.082 || Train Acc: 0.969 || Time: 65.892 s\n",
      "Batch: 170 || Train Loss: 0.023 || Train Acc: 0.984 || Time: 66.014 s\n",
      "Batch: 180 || Train Loss: 0.084 || Train Acc: 0.953 || Time: 66.129 s\n",
      "Batch: 190 || Train Loss: 0.092 || Train Acc: 0.969 || Time: 66.216 s\n",
      "Batch: 200 || Train Loss: 0.144 || Train Acc: 0.938 || Time: 66.285 s\n",
      "Batch: 210 || Train Loss: 0.016 || Train Acc: 1.0 || Time: 66.36 s\n",
      "Batch: 220 || Train Loss: 0.046 || Train Acc: 0.984 || Time: 66.421 s\n",
      "Batch: 230 || Train Loss: 0.156 || Train Acc: 0.969 || Time: 66.476 s\n",
      "Batch: 240 || Train Loss: 0.004 || Train Acc: 1.0 || Time: 66.537 s\n",
      "Batch: 250 || Train Loss: 0.058 || Train Acc: 0.953 || Time: 66.603 s\n",
      "Batch: 260 || Train Loss: 0.087 || Train Acc: 0.984 || Time: 66.686 s\n",
      "Batch: 270 || Train Loss: 0.114 || Train Acc: 0.969 || Time: 66.771 s\n",
      "Batch: 280 || Train Loss: 0.051 || Train Acc: 1.0 || Time: 66.839 s\n",
      "Batch: 290 || Train Loss: 0.192 || Train Acc: 0.922 || Time: 66.937 s\n",
      "Batch: 300 || Train Loss: 0.196 || Train Acc: 0.922 || Time: 67.017 s\n",
      "Batch: 310 || Train Loss: 0.071 || Train Acc: 0.969 || Time: 67.079 s\n",
      "Batch: 320 || Train Loss: 0.145 || Train Acc: 0.953 || Time: 67.144 s\n",
      "Batch: 330 || Train Loss: 0.235 || Train Acc: 0.938 || Time: 67.228 s\n",
      "Batch: 340 || Train Loss: 0.059 || Train Acc: 0.984 || Time: 67.291 s\n",
      "Batch: 350 || Train Loss: 0.286 || Train Acc: 0.906 || Time: 67.353 s\n",
      "Batch: 360 || Train Loss: 0.019 || Train Acc: 1.0 || Time: 67.418 s\n",
      "Batch: 370 || Train Loss: 0.047 || Train Acc: 0.984 || Time: 67.501 s\n",
      "Batch: 380 || Train Loss: 0.012 || Train Acc: 1.0 || Time: 67.563 s\n",
      "Batch: 390 || Train Loss: 0.158 || Train Acc: 0.953 || Time: 67.626 s\n",
      "Batch: 400 || Train Loss: 0.069 || Train Acc: 0.984 || Time: 67.693 s\n",
      "Batch: 410 || Train Loss: 0.022 || Train Acc: 1.0 || Time: 67.778 s\n",
      "Epoch: 17\n",
      "Batch: 10 || Train Loss: 0.035 || Train Acc: 0.984 || Time: 67.858 s\n",
      "Batch: 20 || Train Loss: 0.118 || Train Acc: 0.953 || Time: 67.959 s\n",
      "Batch: 30 || Train Loss: 0.022 || Train Acc: 0.984 || Time: 68.034 s\n",
      "Batch: 40 || Train Loss: 0.024 || Train Acc: 1.0 || Time: 68.108 s\n",
      "Batch: 50 || Train Loss: 0.255 || Train Acc: 0.922 || Time: 68.183 s\n",
      "Batch: 60 || Train Loss: 0.11 || Train Acc: 0.953 || Time: 68.256 s\n",
      "Batch: 70 || Train Loss: 0.078 || Train Acc: 0.984 || Time: 68.345 s\n",
      "Batch: 80 || Train Loss: 0.034 || Train Acc: 0.984 || Time: 68.417 s\n",
      "Batch: 90 || Train Loss: 0.016 || Train Acc: 1.0 || Time: 68.499 s\n",
      "Batch: 100 || Train Loss: 0.111 || Train Acc: 0.953 || Time: 68.562 s\n",
      "Batch: 110 || Train Loss: 0.056 || Train Acc: 0.984 || Time: 68.636 s\n",
      "Batch: 120 || Train Loss: 0.171 || Train Acc: 0.969 || Time: 68.7 s\n",
      "Batch: 130 || Train Loss: 0.022 || Train Acc: 1.0 || Time: 68.835 s\n",
      "Batch: 140 || Train Loss: 0.039 || Train Acc: 0.984 || Time: 68.902 s\n",
      "Batch: 150 || Train Loss: 0.174 || Train Acc: 0.938 || Time: 69.005 s\n",
      "Batch: 160 || Train Loss: 0.121 || Train Acc: 0.969 || Time: 69.078 s\n",
      "Batch: 170 || Train Loss: 0.099 || Train Acc: 0.984 || Time: 69.147 s\n",
      "Batch: 180 || Train Loss: 0.079 || Train Acc: 0.984 || Time: 69.248 s\n",
      "Batch: 190 || Train Loss: 0.074 || Train Acc: 0.969 || Time: 69.33 s\n",
      "Batch: 200 || Train Loss: 0.079 || Train Acc: 0.984 || Time: 69.408 s\n",
      "Batch: 210 || Train Loss: 0.076 || Train Acc: 0.969 || Time: 69.485 s\n",
      "Batch: 220 || Train Loss: 0.026 || Train Acc: 0.984 || Time: 69.558 s\n",
      "Batch: 230 || Train Loss: 0.205 || Train Acc: 0.969 || Time: 69.617 s\n",
      "Batch: 240 || Train Loss: 0.071 || Train Acc: 0.953 || Time: 69.71 s\n",
      "Batch: 250 || Train Loss: 0.036 || Train Acc: 0.984 || Time: 69.768 s\n",
      "Batch: 260 || Train Loss: 0.086 || Train Acc: 0.953 || Time: 69.859 s\n",
      "Batch: 270 || Train Loss: 0.045 || Train Acc: 0.984 || Time: 69.953 s\n",
      "Batch: 280 || Train Loss: 0.127 || Train Acc: 0.938 || Time: 70.032 s\n",
      "Batch: 290 || Train Loss: 0.023 || Train Acc: 1.0 || Time: 70.099 s\n",
      "Batch: 300 || Train Loss: 0.147 || Train Acc: 0.953 || Time: 70.175 s\n",
      "Batch: 310 || Train Loss: 0.092 || Train Acc: 0.984 || Time: 70.248 s\n",
      "Batch: 320 || Train Loss: 0.05 || Train Acc: 0.984 || Time: 70.31 s\n",
      "Batch: 330 || Train Loss: 0.125 || Train Acc: 0.969 || Time: 70.399 s\n",
      "Batch: 340 || Train Loss: 0.104 || Train Acc: 0.953 || Time: 70.475 s\n",
      "Batch: 350 || Train Loss: 0.14 || Train Acc: 0.953 || Time: 70.543 s\n",
      "Batch: 360 || Train Loss: 0.305 || Train Acc: 0.906 || Time: 70.606 s\n",
      "Batch: 370 || Train Loss: 0.028 || Train Acc: 1.0 || Time: 70.674 s\n",
      "Batch: 380 || Train Loss: 0.174 || Train Acc: 0.953 || Time: 70.738 s\n",
      "Batch: 390 || Train Loss: 0.127 || Train Acc: 0.984 || Time: 70.816 s\n",
      "Batch: 400 || Train Loss: 0.127 || Train Acc: 0.922 || Time: 70.882 s\n",
      "Batch: 410 || Train Loss: 0.015 || Train Acc: 1.0 || Time: 70.98 s\n",
      "Epoch: 18\n",
      "Batch: 10 || Train Loss: 0.078 || Train Acc: 0.984 || Time: 71.09 s\n",
      "Batch: 20 || Train Loss: 0.142 || Train Acc: 0.984 || Time: 71.18 s\n",
      "Batch: 30 || Train Loss: 0.184 || Train Acc: 0.953 || Time: 71.271 s\n",
      "Batch: 40 || Train Loss: 0.095 || Train Acc: 0.969 || Time: 71.329 s\n",
      "Batch: 50 || Train Loss: 0.042 || Train Acc: 1.0 || Time: 71.4 s\n",
      "Batch: 60 || Train Loss: 0.177 || Train Acc: 0.953 || Time: 71.463 s\n",
      "Batch: 70 || Train Loss: 0.043 || Train Acc: 0.984 || Time: 71.536 s\n",
      "Batch: 80 || Train Loss: 0.058 || Train Acc: 0.984 || Time: 71.627 s\n",
      "Batch: 90 || Train Loss: 0.081 || Train Acc: 0.969 || Time: 71.714 s\n",
      "Batch: 100 || Train Loss: 0.115 || Train Acc: 0.969 || Time: 71.799 s\n",
      "Batch: 110 || Train Loss: 0.071 || Train Acc: 0.984 || Time: 71.863 s\n",
      "Batch: 120 || Train Loss: 0.012 || Train Acc: 1.0 || Time: 71.95 s\n",
      "Batch: 130 || Train Loss: 0.047 || Train Acc: 0.969 || Time: 72.03 s\n",
      "Batch: 140 || Train Loss: 0.029 || Train Acc: 1.0 || Time: 72.089 s\n",
      "Batch: 150 || Train Loss: 0.087 || Train Acc: 0.969 || Time: 72.166 s\n",
      "Batch: 160 || Train Loss: 0.06 || Train Acc: 0.969 || Time: 72.242 s\n",
      "Batch: 170 || Train Loss: 0.118 || Train Acc: 0.938 || Time: 72.304 s\n",
      "Batch: 180 || Train Loss: 0.004 || Train Acc: 1.0 || Time: 72.363 s\n",
      "Batch: 190 || Train Loss: 0.124 || Train Acc: 0.953 || Time: 72.425 s\n",
      "Batch: 200 || Train Loss: 0.036 || Train Acc: 0.984 || Time: 72.481 s\n",
      "Batch: 210 || Train Loss: 0.074 || Train Acc: 0.984 || Time: 72.561 s\n",
      "Batch: 220 || Train Loss: 0.157 || Train Acc: 0.969 || Time: 72.627 s\n",
      "Batch: 230 || Train Loss: 0.033 || Train Acc: 0.984 || Time: 72.689 s\n",
      "Batch: 240 || Train Loss: 0.132 || Train Acc: 0.953 || Time: 72.755 s\n",
      "Batch: 250 || Train Loss: 0.219 || Train Acc: 0.922 || Time: 72.812 s\n",
      "Batch: 260 || Train Loss: 0.179 || Train Acc: 0.969 || Time: 72.879 s\n",
      "Batch: 270 || Train Loss: 0.111 || Train Acc: 0.969 || Time: 72.961 s\n",
      "Batch: 280 || Train Loss: 0.1 || Train Acc: 0.984 || Time: 73.017 s\n",
      "Batch: 290 || Train Loss: 0.225 || Train Acc: 0.953 || Time: 73.08 s\n",
      "Batch: 300 || Train Loss: 0.011 || Train Acc: 1.0 || Time: 73.139 s\n",
      "Batch: 310 || Train Loss: 0.165 || Train Acc: 0.938 || Time: 73.203 s\n",
      "Batch: 320 || Train Loss: 0.013 || Train Acc: 1.0 || Time: 73.271 s\n",
      "Batch: 330 || Train Loss: 0.055 || Train Acc: 0.984 || Time: 73.328 s\n",
      "Batch: 340 || Train Loss: 0.064 || Train Acc: 0.984 || Time: 73.406 s\n",
      "Batch: 350 || Train Loss: 0.063 || Train Acc: 0.953 || Time: 73.482 s\n",
      "Batch: 360 || Train Loss: 0.037 || Train Acc: 0.984 || Time: 73.548 s\n",
      "Batch: 370 || Train Loss: 0.065 || Train Acc: 0.969 || Time: 73.606 s\n",
      "Batch: 380 || Train Loss: 0.102 || Train Acc: 0.984 || Time: 73.666 s\n",
      "Batch: 390 || Train Loss: 0.061 || Train Acc: 0.984 || Time: 73.73 s\n",
      "Batch: 400 || Train Loss: 0.055 || Train Acc: 0.984 || Time: 73.794 s\n",
      "Batch: 410 || Train Loss: 0.061 || Train Acc: 0.969 || Time: 73.854 s\n",
      "Epoch: 19\n",
      "Batch: 10 || Train Loss: 0.05 || Train Acc: 0.984 || Time: 73.976 s\n",
      "Batch: 20 || Train Loss: 0.053 || Train Acc: 0.969 || Time: 74.053 s\n",
      "Batch: 30 || Train Loss: 0.1 || Train Acc: 0.969 || Time: 74.117 s\n",
      "Batch: 40 || Train Loss: 0.045 || Train Acc: 0.969 || Time: 74.177 s\n",
      "Batch: 50 || Train Loss: 0.026 || Train Acc: 0.984 || Time: 74.24 s\n",
      "Batch: 60 || Train Loss: 0.089 || Train Acc: 0.969 || Time: 74.302 s\n",
      "Batch: 70 || Train Loss: 0.325 || Train Acc: 0.938 || Time: 74.361 s\n",
      "Batch: 80 || Train Loss: 0.062 || Train Acc: 0.953 || Time: 74.424 s\n",
      "Batch: 90 || Train Loss: 0.068 || Train Acc: 0.953 || Time: 74.482 s\n",
      "Batch: 100 || Train Loss: 0.021 || Train Acc: 0.984 || Time: 74.543 s\n",
      "Batch: 110 || Train Loss: 0.082 || Train Acc: 0.969 || Time: 74.615 s\n",
      "Batch: 120 || Train Loss: 0.086 || Train Acc: 0.969 || Time: 74.681 s\n",
      "Batch: 130 || Train Loss: 0.191 || Train Acc: 0.969 || Time: 74.758 s\n",
      "Batch: 140 || Train Loss: 0.078 || Train Acc: 0.969 || Time: 74.833 s\n",
      "Batch: 150 || Train Loss: 0.024 || Train Acc: 0.984 || Time: 74.916 s\n",
      "Batch: 160 || Train Loss: 0.113 || Train Acc: 0.953 || Time: 74.984 s\n",
      "Batch: 170 || Train Loss: 0.069 || Train Acc: 0.984 || Time: 75.044 s\n",
      "Batch: 180 || Train Loss: 0.067 || Train Acc: 0.984 || Time: 75.111 s\n",
      "Batch: 190 || Train Loss: 0.037 || Train Acc: 0.984 || Time: 75.175 s\n",
      "Batch: 200 || Train Loss: 0.14 || Train Acc: 0.922 || Time: 75.25 s\n",
      "Batch: 210 || Train Loss: 0.079 || Train Acc: 0.969 || Time: 75.309 s\n",
      "Batch: 220 || Train Loss: 0.077 || Train Acc: 0.953 || Time: 75.378 s\n",
      "Batch: 230 || Train Loss: 0.118 || Train Acc: 0.938 || Time: 75.438 s\n",
      "Batch: 240 || Train Loss: 0.031 || Train Acc: 0.984 || Time: 75.499 s\n",
      "Batch: 250 || Train Loss: 0.059 || Train Acc: 0.984 || Time: 75.568 s\n",
      "Batch: 260 || Train Loss: 0.065 || Train Acc: 0.969 || Time: 75.658 s\n",
      "Batch: 270 || Train Loss: 0.207 || Train Acc: 0.938 || Time: 75.719 s\n",
      "Batch: 280 || Train Loss: 0.075 || Train Acc: 0.984 || Time: 75.799 s\n",
      "Batch: 290 || Train Loss: 0.076 || Train Acc: 0.969 || Time: 75.862 s\n",
      "Batch: 300 || Train Loss: 0.222 || Train Acc: 0.953 || Time: 75.94 s\n",
      "Batch: 310 || Train Loss: 0.073 || Train Acc: 0.969 || Time: 76.0 s\n",
      "Batch: 320 || Train Loss: 0.098 || Train Acc: 0.969 || Time: 76.071 s\n",
      "Batch: 330 || Train Loss: 0.115 || Train Acc: 0.984 || Time: 76.152 s\n",
      "Batch: 340 || Train Loss: 0.181 || Train Acc: 0.938 || Time: 76.263 s\n",
      "Batch: 350 || Train Loss: 0.086 || Train Acc: 0.969 || Time: 76.372 s\n",
      "Batch: 360 || Train Loss: 0.088 || Train Acc: 0.969 || Time: 76.466 s\n",
      "Batch: 370 || Train Loss: 0.099 || Train Acc: 0.984 || Time: 76.571 s\n",
      "Batch: 380 || Train Loss: 0.166 || Train Acc: 0.953 || Time: 76.673 s\n",
      "Batch: 390 || Train Loss: 0.272 || Train Acc: 0.875 || Time: 76.782 s\n",
      "Batch: 400 || Train Loss: 0.052 || Train Acc: 0.984 || Time: 77.018 s\n",
      "Batch: 410 || Train Loss: 0.103 || Train Acc: 0.969 || Time: 77.128 s\n",
      "Epoch: 20\n",
      "Batch: 10 || Train Loss: 0.05 || Train Acc: 0.984 || Time: 77.215 s\n",
      "Batch: 20 || Train Loss: 0.264 || Train Acc: 0.938 || Time: 77.287 s\n",
      "Batch: 30 || Train Loss: 0.088 || Train Acc: 0.953 || Time: 77.379 s\n",
      "Batch: 40 || Train Loss: 0.062 || Train Acc: 0.984 || Time: 77.441 s\n",
      "Batch: 50 || Train Loss: 0.021 || Train Acc: 1.0 || Time: 77.51 s\n",
      "Batch: 60 || Train Loss: 0.085 || Train Acc: 0.969 || Time: 77.578 s\n",
      "Batch: 70 || Train Loss: 0.12 || Train Acc: 0.938 || Time: 77.642 s\n",
      "Batch: 80 || Train Loss: 0.041 || Train Acc: 0.984 || Time: 77.714 s\n",
      "Batch: 90 || Train Loss: 0.058 || Train Acc: 0.969 || Time: 77.79 s\n",
      "Batch: 100 || Train Loss: 0.113 || Train Acc: 0.953 || Time: 77.878 s\n",
      "Batch: 110 || Train Loss: 0.121 || Train Acc: 0.969 || Time: 77.973 s\n",
      "Batch: 120 || Train Loss: 0.016 || Train Acc: 1.0 || Time: 78.049 s\n",
      "Batch: 130 || Train Loss: 0.031 || Train Acc: 0.984 || Time: 78.11 s\n",
      "Batch: 140 || Train Loss: 0.026 || Train Acc: 0.984 || Time: 78.172 s\n",
      "Batch: 150 || Train Loss: 0.085 || Train Acc: 0.969 || Time: 78.236 s\n",
      "Batch: 160 || Train Loss: 0.209 || Train Acc: 0.969 || Time: 78.31 s\n",
      "Batch: 170 || Train Loss: 0.005 || Train Acc: 1.0 || Time: 78.378 s\n",
      "Batch: 180 || Train Loss: 0.106 || Train Acc: 0.969 || Time: 78.437 s\n",
      "Batch: 190 || Train Loss: 0.016 || Train Acc: 1.0 || Time: 78.496 s\n",
      "Batch: 200 || Train Loss: 0.153 || Train Acc: 0.953 || Time: 78.567 s\n",
      "Batch: 210 || Train Loss: 0.073 || Train Acc: 0.953 || Time: 78.649 s\n",
      "Batch: 220 || Train Loss: 0.068 || Train Acc: 0.969 || Time: 78.706 s\n",
      "Batch: 230 || Train Loss: 0.014 || Train Acc: 1.0 || Time: 78.775 s\n",
      "Batch: 240 || Train Loss: 0.048 || Train Acc: 0.984 || Time: 78.841 s\n",
      "Batch: 250 || Train Loss: 0.083 || Train Acc: 0.953 || Time: 78.931 s\n",
      "Batch: 260 || Train Loss: 0.023 || Train Acc: 1.0 || Time: 79.005 s\n",
      "Batch: 270 || Train Loss: 0.059 || Train Acc: 0.984 || Time: 79.061 s\n",
      "Batch: 280 || Train Loss: 0.148 || Train Acc: 0.969 || Time: 79.151 s\n",
      "Batch: 290 || Train Loss: 0.081 || Train Acc: 0.953 || Time: 79.229 s\n",
      "Batch: 300 || Train Loss: 0.355 || Train Acc: 0.906 || Time: 79.295 s\n",
      "Batch: 310 || Train Loss: 0.099 || Train Acc: 0.969 || Time: 79.492 s\n",
      "Batch: 320 || Train Loss: 0.151 || Train Acc: 0.953 || Time: 79.56 s\n",
      "Batch: 330 || Train Loss: 0.018 || Train Acc: 1.0 || Time: 79.62 s\n",
      "Batch: 340 || Train Loss: 0.107 || Train Acc: 0.953 || Time: 79.696 s\n",
      "Batch: 350 || Train Loss: 0.044 || Train Acc: 0.984 || Time: 79.79 s\n",
      "Batch: 360 || Train Loss: 0.1 || Train Acc: 0.953 || Time: 79.912 s\n",
      "Batch: 370 || Train Loss: 0.141 || Train Acc: 0.938 || Time: 80.037 s\n",
      "Batch: 380 || Train Loss: 0.043 || Train Acc: 0.984 || Time: 80.14 s\n",
      "Batch: 390 || Train Loss: 0.084 || Train Acc: 0.984 || Time: 80.246 s\n",
      "Batch: 400 || Train Loss: 0.052 || Train Acc: 0.969 || Time: 80.363 s\n",
      "Batch: 410 || Train Loss: 0.07 || Train Acc: 0.969 || Time: 80.469 s\n"
     ]
    }
   ],
   "source": [
    "#Esto también usualmente se pone dentro de una función: training_loop.\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "print(\"STARTING TRAINING ...\\n\")\n",
    "\n",
    "train_losses, valid_losses = [], []\n",
    "train_acc, valid_acc = [], []\n",
    "\n",
    "for epoch in range(20): #Definiendo 20 epocas.\n",
    "  red_neuronal = red_neuronal.train()\n",
    "  print(\"Epoch: {}\".format(epoch+1))\n",
    "  batch_train_losses, batch_train_acc = [], []\n",
    "\n",
    "  batch = 0\n",
    "  for train_batch in train_loader: #Objeto DataLoader\n",
    "\n",
    "    train_X, train_y = train_batch.values()\n",
    "\n",
    "    train_X = train_X.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "\n",
    "    train_preds = red_neuronal.forward(train_X)\n",
    "    train_loss = cross_entropy_loss(train_y, train_preds)\n",
    "\n",
    "    train_accuracy = accuracy(train_y, train_preds)\n",
    "\n",
    "    optimizer.zero_grad() # ????\n",
    "    train_loss.backward() #Back prop?\n",
    "\n",
    "    optimizer.step() #\n",
    "\n",
    "    train_loss = np.round(train_loss.item(), 3)\n",
    "    train_accuracy = np.round(train_accuracy.item(),3)\n",
    "\n",
    "    end = time.time()\n",
    "    batch = batch + 1\n",
    "    log = batch % 10 == 0\n",
    "\n",
    "    time_delta = np.round(end - start, 3)\n",
    "\n",
    "    batch_train_losses.append(train_loss)\n",
    "    batch_train_acc.append(train_accuracy)\n",
    "\n",
    "    logs = \"Batch: {} || Train Loss: {} || Train Acc: {} || Time: {} s\"\n",
    "    \n",
    "    if log:\n",
    "        print(logs.format(batch, train_loss, train_accuracy, time_delta))\n",
    "\n",
    "  #Hasta acá solo hemos entrenado. Aún no evaluamos con respecto al test. \n",
    "\n",
    "  train_losses.append(np.mean(batch_train_losses))\n",
    "  train_acc.append(np.mean(batch_train_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZmUb8zsj4jF-",
    "outputId": "e7298ecd-cac7-4438-a230-3ca714ef33a9"
   },
   "source": [
    "### Guardamos el modelo.\n",
    "\n",
    "Esto lo podemos hacer de dos formas:\n",
    "\n",
    "    - Serializando: Que implica guardalos como un objeto pickle y abrir también con ello.\n",
    "    \n",
    "    - Guardando solo el state_dict: Que es guardar los parámetros del modelo (más sencillo) e importar\n",
    "        todos estos junto con la arquitectura sola del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(red_neuronal, 'mnist_model.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Pytorch MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

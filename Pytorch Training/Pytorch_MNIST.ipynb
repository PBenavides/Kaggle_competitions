{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyADoevEiWGw"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from collections import Counter"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98iEMpHhig34"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ziHZPr0irZn"
      },
      "source": [
        "#### Creamos nuestra clase de datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a2MrbiLiqfG"
      },
      "source": [
        "links_csv = ['https://raw.githubusercontent.com/HackSpacePeru/Datasets_intro_Data_Science/master/train1.csv',\r\n",
        "'https://raw.githubusercontent.com/HackSpacePeru/Datasets_intro_Data_Science/master/train2.csv',\r\n",
        "'https://raw.githubusercontent.com/HackSpacePeru/Datasets_intro_Data_Science/master/train3.csv',\r\n",
        "'https://raw.githubusercontent.com/HackSpacePeru/Datasets_intro_Data_Science/master/train4.csv',]\r\n",
        "\r\n",
        "class MNISTDataset(Dataset):\r\n",
        "  def __init__(self, links_csv, mode='train'):\r\n",
        "    self.mode = mode #\r\n",
        "    list_df = [pd.read_csv(link) for link in links_csv]\r\n",
        "    data = pd.concat(list_df)\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    <---------------------------- Preprocesamiento de Datos -------------------------------------->\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    if self.mode == 'train':\r\n",
        "      self.features = data.drop('label',axis=1).values/255.0\r\n",
        "      self.target = data['label'].values\r\n",
        "      #Reshaping\r\n",
        "      self.target = self.target.reshape((-1,1)) #Dejando q se reeshapee solo\r\n",
        "\r\n",
        "    else:\r\n",
        "      self.features = data.values/255.0\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.features)\r\n",
        "\r\n",
        "  def __getitem__(self, idx):\r\n",
        "    if self.mode=='train':\r\n",
        "      feat = torch.Tensor(self.features[idx])\r\n",
        "      oupt = torch.Tensor(self.target[idx])\r\n",
        "\r\n",
        "      return {'features':feat,\r\n",
        "              'target':oupt,}\r\n",
        "      \r\n",
        "    else:\r\n",
        "      feat = torch.Tensor(self.features[idx])\r\n",
        "      return {'features':feat}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcqLFzS7lW72"
      },
      "source": [
        "test_links = ['https://raw.githubusercontent.com/HackSpacePeru/Datasets_intro_Data_Science/master/test.csv']\r\n",
        "\r\n",
        "train = MNISTDataset(links_csv = links_csv, mode='train')\r\n",
        "test = MNISTDataset(links_csv=test_links, mode='test')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vfqHtHnpfO3"
      },
      "source": [
        "#Ahora vamos a crear los DataLoades para poder obtener los batchs.\r\n",
        "\r\n",
        "train_loader = DataLoader(train, batch_size=64, shuffle = True)\r\n",
        "test_loader = DataLoader(test, batch_size=64, shuffle =True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sELOndA6uSLL"
      },
      "source": [
        "### Modelling MultiLayerPerceptron (MLP)\r\n",
        "\r\n",
        "Vamos a ver que primero haremos una clase heredada de la clase nn.Module, y también usaremos super() para poder heredar los atributos de la clase nn.Module. Así tendremos acceso y más flexibilidad para extender esta clase nn.Module. \r\n",
        "\r\n",
        "#### Definiendo el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9j4SPG8m4Yd"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "\r\n",
        "class MLP(nn.Module):\r\n",
        "  def __init__(self, i, u, v, o):\r\n",
        "    \"\"\"\r\n",
        "    Donde i,u,v,o son los números de neuronas de \r\n",
        "    entrada y salida que tendrá mi red.\r\n",
        "    \"\"\"\r\n",
        "    super(MLP, self).__init__()\r\n",
        "    self.relu_layer = nn.ReLU()\r\n",
        "    self.dense_1 = nn.Linear(i, u)\r\n",
        "    self.b1 = nn.BatchNorm1d(20)\r\n",
        "    self.dense_2 = nn.Linear(u,v)\r\n",
        "    self.dense_output = nn.Linear(v, o)\r\n",
        "\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.relu_layer(self.dense_1(x)) # activation( Capa )\r\n",
        "    x = self.b1(x) #Batch Layer\r\n",
        "    x = self.relu_layer(self.dense_2(x)) # Activation(Capa)\r\n",
        "\r\n",
        "    logits = self.dense_output(x)\r\n",
        "\r\n",
        "    return logits"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM0ZolwAxzxU"
      },
      "source": [
        "### Inicializando la red:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K009xLfCx1Q6",
        "outputId": "f2df5ed4-e50b-4669-ac2c-b8fae9f368b3"
      },
      "source": [
        "from torch.optim import Adam\r\n",
        "\r\n",
        "#Usamos el GPU\r\n",
        "device = torch.device('cuda')\r\n",
        "red_neuronal = MLP(i=784, u = 20, v=20, o = 10).to(device) #Acá puedo definir los layers <- Notar nombre de objeto.\r\n",
        "optimizer = Adam(params=red_neuronal.parameters(), lr=0.01)\r\n",
        "print(red_neuronal) #Imprimimos la arquitectura"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (relu_layer): ReLU()\n",
            "  (dense_1): Linear(in_features=784, out_features=20, bias=True)\n",
            "  (b1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dense_2): Linear(in_features=20, out_features=20, bias=True)\n",
            "  (dense_output): Linear(in_features=20, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0I5hBwAyObV"
      },
      "source": [
        "#Definimos nuestra función de pérdida\r\n",
        "\r\n",
        "def accuracy(y_true, y_pred):\r\n",
        "  y_true = y_true.long().squeeze()\r\n",
        "  y_pred = torch.argmax(y_pred, axis=1)\r\n",
        "  return (y_true == y_pred).float().sum()/len(y_true)\r\n",
        "\r\n",
        "def cross_entropy_loss(y_true, y_pred):\r\n",
        "  y_true = y_true.long().squeeze()\r\n",
        "  return nn.CrossEntropyLoss()(y_pred, y_true)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxmuVKtszz3H"
      },
      "source": [
        "### Entrenando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZVF3Igazoer",
        "outputId": "be8688d3-6892-45fe-a0b5-98fedfda715e"
      },
      "source": [
        "#Esto también usualmente se pone dentro de una función: training_loop.\r\n",
        "\r\n",
        "import time\r\n",
        "start = time.time()\r\n",
        "print(\"STARTING TRAINING ...\\n\")\r\n",
        "\r\n",
        "train_losses, valid_losses = [], []\r\n",
        "train_acc, valid_acc = [], []\r\n",
        "\r\n",
        "for epoch in range(20): #Definiendo 20 epocas.\r\n",
        "  red_neuronal = red_neuronal.train()\r\n",
        "  print(\"Epoch: {}\".format(epoch+1))\r\n",
        "  batch_train_losses, batch_train_acc = [], []\r\n",
        "\r\n",
        "  batch = 0\r\n",
        "  for train_batch in train_loader: #Objeto DataLoader\r\n",
        "\r\n",
        "    train_X, train_y = train_batch.values()\r\n",
        "\r\n",
        "    train_X = train_X.to(device)\r\n",
        "    train_y = train_y.to(device)\r\n",
        "\r\n",
        "    train_preds = red_neuronal.forward(train_X)\r\n",
        "    train_loss = cross_entropy_loss(train_y, train_preds)\r\n",
        "\r\n",
        "    train_accuracy = accuracy(train_y, train_preds)\r\n",
        "\r\n",
        "    optimizer.zero_grad() # ????\r\n",
        "    train_loss.backward() #Back prop?\r\n",
        "\r\n",
        "    optimizer.step() #\r\n",
        "\r\n",
        "    train_loss = np.round(train_loss.item(), 3)\r\n",
        "    train_accuracy = np.round(train_accuracy.item(),3)\r\n",
        "\r\n",
        "    end = time.time()\r\n",
        "    batch = batch + 1\r\n",
        "    log = batch % 10 == 0\r\n",
        "\r\n",
        "    time_delta = np.round(end - start, 3)\r\n",
        "\r\n",
        "    batch_train_losses.append(train_loss)\r\n",
        "    batch_train_acc.append(train_accuracy)\r\n",
        "\r\n",
        "    logs = \"Batch: {} || Train Loss: {} || Train Acc: {} || Time: {} s\"\r\n",
        "    if log: print(logs.format(batch, train_loss, train_acc, time_delta))\r\n",
        "\r\n",
        "  #Hasta acá solo hemos entrenado. Aún no evaluamos con respecto al test. \r\n",
        "\r\n",
        "  train_losses.append(np.mean(batch_train_losses))\r\n",
        "  train_acc.append(np.mean(batch_train_acc))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STARTING TRAINING ...\n",
            "\n",
            "Epoch: 1\n",
            "Batch: 10 || Train Loss: 1.449 || Train Acc: [] || Time: 0.038 s\n",
            "Batch: 20 || Train Loss: 1.0 || Train Acc: [] || Time: 0.073 s\n",
            "Batch: 30 || Train Loss: 0.662 || Train Acc: [] || Time: 0.11 s\n",
            "Batch: 40 || Train Loss: 0.548 || Train Acc: [] || Time: 0.147 s\n",
            "Batch: 50 || Train Loss: 0.522 || Train Acc: [] || Time: 0.182 s\n",
            "Batch: 60 || Train Loss: 0.558 || Train Acc: [] || Time: 0.221 s\n",
            "Batch: 70 || Train Loss: 0.434 || Train Acc: [] || Time: 0.256 s\n",
            "Batch: 80 || Train Loss: 0.341 || Train Acc: [] || Time: 0.295 s\n",
            "Batch: 90 || Train Loss: 0.518 || Train Acc: [] || Time: 0.329 s\n",
            "Batch: 100 || Train Loss: 0.637 || Train Acc: [] || Time: 0.363 s\n",
            "Batch: 110 || Train Loss: 0.181 || Train Acc: [] || Time: 0.396 s\n",
            "Batch: 120 || Train Loss: 0.383 || Train Acc: [] || Time: 0.433 s\n",
            "Batch: 130 || Train Loss: 0.466 || Train Acc: [] || Time: 0.469 s\n",
            "Batch: 140 || Train Loss: 0.325 || Train Acc: [] || Time: 0.504 s\n",
            "Batch: 150 || Train Loss: 0.313 || Train Acc: [] || Time: 0.539 s\n",
            "Batch: 160 || Train Loss: 0.261 || Train Acc: [] || Time: 0.572 s\n",
            "Batch: 170 || Train Loss: 0.405 || Train Acc: [] || Time: 0.605 s\n",
            "Batch: 180 || Train Loss: 0.154 || Train Acc: [] || Time: 0.642 s\n",
            "Batch: 190 || Train Loss: 0.41 || Train Acc: [] || Time: 0.68 s\n",
            "Batch: 200 || Train Loss: 0.33 || Train Acc: [] || Time: 0.72 s\n",
            "Batch: 210 || Train Loss: 0.363 || Train Acc: [] || Time: 0.754 s\n",
            "Batch: 220 || Train Loss: 0.18 || Train Acc: [] || Time: 0.79 s\n",
            "Batch: 230 || Train Loss: 0.323 || Train Acc: [] || Time: 0.827 s\n",
            "Batch: 240 || Train Loss: 0.352 || Train Acc: [] || Time: 0.865 s\n",
            "Batch: 250 || Train Loss: 0.152 || Train Acc: [] || Time: 0.903 s\n",
            "Batch: 260 || Train Loss: 0.242 || Train Acc: [] || Time: 0.938 s\n",
            "Batch: 270 || Train Loss: 0.288 || Train Acc: [] || Time: 0.972 s\n",
            "Batch: 280 || Train Loss: 0.271 || Train Acc: [] || Time: 1.007 s\n",
            "Batch: 290 || Train Loss: 0.441 || Train Acc: [] || Time: 1.046 s\n",
            "Batch: 300 || Train Loss: 0.469 || Train Acc: [] || Time: 1.083 s\n",
            "Batch: 310 || Train Loss: 0.425 || Train Acc: [] || Time: 1.123 s\n",
            "Batch: 320 || Train Loss: 0.342 || Train Acc: [] || Time: 1.158 s\n",
            "Batch: 330 || Train Loss: 0.232 || Train Acc: [] || Time: 1.198 s\n",
            "Batch: 340 || Train Loss: 0.327 || Train Acc: [] || Time: 1.233 s\n",
            "Batch: 350 || Train Loss: 0.233 || Train Acc: [] || Time: 1.266 s\n",
            "Batch: 360 || Train Loss: 0.203 || Train Acc: [] || Time: 1.304 s\n",
            "Batch: 370 || Train Loss: 0.174 || Train Acc: [] || Time: 1.34 s\n",
            "Batch: 380 || Train Loss: 0.406 || Train Acc: [] || Time: 1.375 s\n",
            "Batch: 390 || Train Loss: 0.145 || Train Acc: [] || Time: 1.41 s\n",
            "Batch: 400 || Train Loss: 0.145 || Train Acc: [] || Time: 1.444 s\n",
            "Batch: 410 || Train Loss: 0.324 || Train Acc: [] || Time: 1.477 s\n",
            "Epoch: 2\n",
            "Batch: 10 || Train Loss: 0.227 || Train Acc: [0.8758212560386475] || Time: 1.53 s\n",
            "Batch: 20 || Train Loss: 0.217 || Train Acc: [0.8758212560386475] || Time: 1.567 s\n",
            "Batch: 30 || Train Loss: 0.087 || Train Acc: [0.8758212560386475] || Time: 1.601 s\n",
            "Batch: 40 || Train Loss: 0.297 || Train Acc: [0.8758212560386475] || Time: 1.636 s\n",
            "Batch: 50 || Train Loss: 0.429 || Train Acc: [0.8758212560386475] || Time: 1.671 s\n",
            "Batch: 60 || Train Loss: 0.208 || Train Acc: [0.8758212560386475] || Time: 1.709 s\n",
            "Batch: 70 || Train Loss: 0.283 || Train Acc: [0.8758212560386475] || Time: 1.745 s\n",
            "Batch: 80 || Train Loss: 0.247 || Train Acc: [0.8758212560386475] || Time: 1.779 s\n",
            "Batch: 90 || Train Loss: 0.319 || Train Acc: [0.8758212560386475] || Time: 1.813 s\n",
            "Batch: 100 || Train Loss: 0.232 || Train Acc: [0.8758212560386475] || Time: 1.847 s\n",
            "Batch: 110 || Train Loss: 0.324 || Train Acc: [0.8758212560386475] || Time: 1.884 s\n",
            "Batch: 120 || Train Loss: 0.272 || Train Acc: [0.8758212560386475] || Time: 1.918 s\n",
            "Batch: 130 || Train Loss: 0.14 || Train Acc: [0.8758212560386475] || Time: 1.955 s\n",
            "Batch: 140 || Train Loss: 0.45 || Train Acc: [0.8758212560386475] || Time: 1.99 s\n",
            "Batch: 150 || Train Loss: 0.484 || Train Acc: [0.8758212560386475] || Time: 2.023 s\n",
            "Batch: 160 || Train Loss: 0.321 || Train Acc: [0.8758212560386475] || Time: 2.057 s\n",
            "Batch: 170 || Train Loss: 0.275 || Train Acc: [0.8758212560386475] || Time: 2.093 s\n",
            "Batch: 180 || Train Loss: 0.34 || Train Acc: [0.8758212560386475] || Time: 2.127 s\n",
            "Batch: 190 || Train Loss: 0.224 || Train Acc: [0.8758212560386475] || Time: 2.164 s\n",
            "Batch: 200 || Train Loss: 0.106 || Train Acc: [0.8758212560386475] || Time: 2.198 s\n",
            "Batch: 210 || Train Loss: 0.072 || Train Acc: [0.8758212560386475] || Time: 2.232 s\n",
            "Batch: 220 || Train Loss: 0.071 || Train Acc: [0.8758212560386475] || Time: 2.266 s\n",
            "Batch: 230 || Train Loss: 0.152 || Train Acc: [0.8758212560386475] || Time: 2.3 s\n",
            "Batch: 240 || Train Loss: 0.364 || Train Acc: [0.8758212560386475] || Time: 2.337 s\n",
            "Batch: 250 || Train Loss: 0.141 || Train Acc: [0.8758212560386475] || Time: 2.374 s\n",
            "Batch: 260 || Train Loss: 0.277 || Train Acc: [0.8758212560386475] || Time: 2.408 s\n",
            "Batch: 270 || Train Loss: 0.213 || Train Acc: [0.8758212560386475] || Time: 2.45 s\n",
            "Batch: 280 || Train Loss: 0.1 || Train Acc: [0.8758212560386475] || Time: 2.486 s\n",
            "Batch: 290 || Train Loss: 0.159 || Train Acc: [0.8758212560386475] || Time: 2.528 s\n",
            "Batch: 300 || Train Loss: 0.43 || Train Acc: [0.8758212560386475] || Time: 2.562 s\n",
            "Batch: 310 || Train Loss: 0.177 || Train Acc: [0.8758212560386475] || Time: 2.598 s\n",
            "Batch: 320 || Train Loss: 0.2 || Train Acc: [0.8758212560386475] || Time: 2.632 s\n",
            "Batch: 330 || Train Loss: 0.096 || Train Acc: [0.8758212560386475] || Time: 2.666 s\n",
            "Batch: 340 || Train Loss: 0.443 || Train Acc: [0.8758212560386475] || Time: 2.7 s\n",
            "Batch: 350 || Train Loss: 0.055 || Train Acc: [0.8758212560386475] || Time: 2.74 s\n",
            "Batch: 360 || Train Loss: 0.093 || Train Acc: [0.8758212560386475] || Time: 2.774 s\n",
            "Batch: 370 || Train Loss: 0.19 || Train Acc: [0.8758212560386475] || Time: 2.811 s\n",
            "Batch: 380 || Train Loss: 0.171 || Train Acc: [0.8758212560386475] || Time: 2.844 s\n",
            "Batch: 390 || Train Loss: 0.25 || Train Acc: [0.8758212560386475] || Time: 2.878 s\n",
            "Batch: 400 || Train Loss: 0.173 || Train Acc: [0.8758212560386475] || Time: 2.912 s\n",
            "Batch: 410 || Train Loss: 0.135 || Train Acc: [0.8758212560386475] || Time: 2.949 s\n",
            "Epoch: 3\n",
            "Batch: 10 || Train Loss: 0.218 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 2.998 s\n",
            "Batch: 20 || Train Loss: 0.148 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.035 s\n",
            "Batch: 30 || Train Loss: 0.151 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.07 s\n",
            "Batch: 40 || Train Loss: 0.136 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.105 s\n",
            "Batch: 50 || Train Loss: 0.15 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.14 s\n",
            "Batch: 60 || Train Loss: 0.303 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.178 s\n",
            "Batch: 70 || Train Loss: 0.31 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.215 s\n",
            "Batch: 80 || Train Loss: 0.172 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.262 s\n",
            "Batch: 90 || Train Loss: 0.078 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.297 s\n",
            "Batch: 100 || Train Loss: 0.078 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.33 s\n",
            "Batch: 110 || Train Loss: 0.058 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.364 s\n",
            "Batch: 120 || Train Loss: 0.122 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.398 s\n",
            "Batch: 130 || Train Loss: 0.208 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.432 s\n",
            "Batch: 140 || Train Loss: 0.221 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.471 s\n",
            "Batch: 150 || Train Loss: 0.329 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.506 s\n",
            "Batch: 160 || Train Loss: 0.197 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.541 s\n",
            "Batch: 170 || Train Loss: 0.089 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.575 s\n",
            "Batch: 180 || Train Loss: 0.146 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.609 s\n",
            "Batch: 190 || Train Loss: 0.088 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.643 s\n",
            "Batch: 200 || Train Loss: 0.275 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.68 s\n",
            "Batch: 210 || Train Loss: 0.086 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.718 s\n",
            "Batch: 220 || Train Loss: 0.079 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.758 s\n",
            "Batch: 230 || Train Loss: 0.198 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.794 s\n",
            "Batch: 240 || Train Loss: 0.202 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.829 s\n",
            "Batch: 250 || Train Loss: 0.223 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.863 s\n",
            "Batch: 260 || Train Loss: 0.184 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.901 s\n",
            "Batch: 270 || Train Loss: 0.135 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.938 s\n",
            "Batch: 280 || Train Loss: 0.061 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 3.972 s\n",
            "Batch: 290 || Train Loss: 0.206 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 4.007 s\n",
            "Batch: 300 || Train Loss: 0.159 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 4.042 s\n",
            "Batch: 310 || Train Loss: 0.218 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 4.075 s\n",
            "Batch: 320 || Train Loss: 0.218 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 4.113 s\n",
            "Batch: 330 || Train Loss: 0.184 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 4.15 s\n",
            "Batch: 340 || Train Loss: 0.078 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 4.186 s\n",
            "Batch: 350 || Train Loss: 0.17 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 4.22 s\n",
            "Batch: 360 || Train Loss: 0.214 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 4.254 s\n",
            "Batch: 370 || Train Loss: 0.18 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 4.29 s\n",
            "Batch: 380 || Train Loss: 0.09 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 4.328 s\n",
            "Batch: 390 || Train Loss: 0.179 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 4.364 s\n",
            "Batch: 400 || Train Loss: 0.143 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 4.399 s\n",
            "Batch: 410 || Train Loss: 0.149 || Train Acc: [0.8758212560386475, 0.9336231884057972] || Time: 4.433 s\n",
            "Epoch: 4\n",
            "Batch: 10 || Train Loss: 0.184 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.48 s\n",
            "Batch: 20 || Train Loss: 0.271 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.514 s\n",
            "Batch: 30 || Train Loss: 0.103 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.552 s\n",
            "Batch: 40 || Train Loss: 0.102 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.585 s\n",
            "Batch: 50 || Train Loss: 0.181 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.619 s\n",
            "Batch: 60 || Train Loss: 0.15 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.652 s\n",
            "Batch: 70 || Train Loss: 0.159 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.685 s\n",
            "Batch: 80 || Train Loss: 0.068 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.718 s\n",
            "Batch: 90 || Train Loss: 0.05 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.761 s\n",
            "Batch: 100 || Train Loss: 0.154 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.795 s\n",
            "Batch: 110 || Train Loss: 0.139 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.828 s\n",
            "Batch: 120 || Train Loss: 0.049 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.862 s\n",
            "Batch: 130 || Train Loss: 0.241 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.895 s\n",
            "Batch: 140 || Train Loss: 0.237 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.929 s\n",
            "Batch: 150 || Train Loss: 0.077 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 4.969 s\n",
            "Batch: 160 || Train Loss: 0.028 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.012 s\n",
            "Batch: 170 || Train Loss: 0.265 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.047 s\n",
            "Batch: 180 || Train Loss: 0.1 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.081 s\n",
            "Batch: 190 || Train Loss: 0.14 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.114 s\n",
            "Batch: 200 || Train Loss: 0.094 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.147 s\n",
            "Batch: 210 || Train Loss: 0.221 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.184 s\n",
            "Batch: 220 || Train Loss: 0.219 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.218 s\n",
            "Batch: 230 || Train Loss: 0.221 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.252 s\n",
            "Batch: 240 || Train Loss: 0.064 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.285 s\n",
            "Batch: 250 || Train Loss: 0.186 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.319 s\n",
            "Batch: 260 || Train Loss: 0.178 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.352 s\n",
            "Batch: 270 || Train Loss: 0.131 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.392 s\n",
            "Batch: 280 || Train Loss: 0.128 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.428 s\n",
            "Batch: 290 || Train Loss: 0.112 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.462 s\n",
            "Batch: 300 || Train Loss: 0.215 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.496 s\n",
            "Batch: 310 || Train Loss: 0.046 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.531 s\n",
            "Batch: 320 || Train Loss: 0.095 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.564 s\n",
            "Batch: 330 || Train Loss: 0.142 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.6 s\n",
            "Batch: 340 || Train Loss: 0.133 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.633 s\n",
            "Batch: 350 || Train Loss: 0.318 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.671 s\n",
            "Batch: 360 || Train Loss: 0.269 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.705 s\n",
            "Batch: 370 || Train Loss: 0.043 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.739 s\n",
            "Batch: 380 || Train Loss: 0.175 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.777 s\n",
            "Batch: 390 || Train Loss: 0.2 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.817 s\n",
            "Batch: 400 || Train Loss: 0.194 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.853 s\n",
            "Batch: 410 || Train Loss: 0.304 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831] || Time: 5.89 s\n",
            "Epoch: 5\n",
            "Batch: 10 || Train Loss: 0.11 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 5.938 s\n",
            "Batch: 20 || Train Loss: 0.113 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 5.972 s\n",
            "Batch: 30 || Train Loss: 0.176 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.007 s\n",
            "Batch: 40 || Train Loss: 0.189 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.044 s\n",
            "Batch: 50 || Train Loss: 0.188 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.077 s\n",
            "Batch: 60 || Train Loss: 0.158 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.114 s\n",
            "Batch: 70 || Train Loss: 0.422 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.147 s\n",
            "Batch: 80 || Train Loss: 0.04 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.18 s\n",
            "Batch: 90 || Train Loss: 0.155 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.215 s\n",
            "Batch: 100 || Train Loss: 0.17 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.253 s\n",
            "Batch: 110 || Train Loss: 0.14 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.301 s\n",
            "Batch: 120 || Train Loss: 0.07 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.341 s\n",
            "Batch: 130 || Train Loss: 0.099 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.384 s\n",
            "Batch: 140 || Train Loss: 0.132 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.424 s\n",
            "Batch: 150 || Train Loss: 0.131 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.467 s\n",
            "Batch: 160 || Train Loss: 0.103 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.503 s\n",
            "Batch: 170 || Train Loss: 0.136 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.538 s\n",
            "Batch: 180 || Train Loss: 0.127 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.572 s\n",
            "Batch: 190 || Train Loss: 0.197 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.607 s\n",
            "Batch: 200 || Train Loss: 0.233 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.641 s\n",
            "Batch: 210 || Train Loss: 0.129 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.678 s\n",
            "Batch: 220 || Train Loss: 0.066 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.712 s\n",
            "Batch: 230 || Train Loss: 0.306 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.745 s\n",
            "Batch: 240 || Train Loss: 0.127 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.785 s\n",
            "Batch: 250 || Train Loss: 0.143 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.821 s\n",
            "Batch: 260 || Train Loss: 0.22 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.854 s\n",
            "Batch: 270 || Train Loss: 0.143 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.891 s\n",
            "Batch: 280 || Train Loss: 0.068 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.925 s\n",
            "Batch: 290 || Train Loss: 0.165 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.958 s\n",
            "Batch: 300 || Train Loss: 0.139 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 6.993 s\n",
            "Batch: 310 || Train Loss: 0.207 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 7.029 s\n",
            "Batch: 320 || Train Loss: 0.167 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 7.064 s\n",
            "Batch: 330 || Train Loss: 0.184 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 7.102 s\n",
            "Batch: 340 || Train Loss: 0.046 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 7.137 s\n",
            "Batch: 350 || Train Loss: 0.182 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 7.171 s\n",
            "Batch: 360 || Train Loss: 0.077 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 7.205 s\n",
            "Batch: 370 || Train Loss: 0.103 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 7.242 s\n",
            "Batch: 380 || Train Loss: 0.083 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 7.277 s\n",
            "Batch: 390 || Train Loss: 0.073 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 7.315 s\n",
            "Batch: 400 || Train Loss: 0.219 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 7.348 s\n",
            "Batch: 410 || Train Loss: 0.098 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015] || Time: 7.383 s\n",
            "Epoch: 6\n",
            "Batch: 10 || Train Loss: 0.102 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.433 s\n",
            "Batch: 20 || Train Loss: 0.067 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.47 s\n",
            "Batch: 30 || Train Loss: 0.026 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.505 s\n",
            "Batch: 40 || Train Loss: 0.169 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.543 s\n",
            "Batch: 50 || Train Loss: 0.162 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.577 s\n",
            "Batch: 60 || Train Loss: 0.008 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.619 s\n",
            "Batch: 70 || Train Loss: 0.301 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.659 s\n",
            "Batch: 80 || Train Loss: 0.295 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.694 s\n",
            "Batch: 90 || Train Loss: 0.101 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.727 s\n",
            "Batch: 100 || Train Loss: 0.113 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.764 s\n",
            "Batch: 110 || Train Loss: 0.341 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.802 s\n",
            "Batch: 120 || Train Loss: 0.125 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.835 s\n",
            "Batch: 130 || Train Loss: 0.108 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.87 s\n",
            "Batch: 140 || Train Loss: 0.194 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.904 s\n",
            "Batch: 150 || Train Loss: 0.052 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.937 s\n",
            "Batch: 160 || Train Loss: 0.174 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 7.974 s\n",
            "Batch: 170 || Train Loss: 0.077 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.008 s\n",
            "Batch: 180 || Train Loss: 0.093 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.041 s\n",
            "Batch: 190 || Train Loss: 0.047 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.075 s\n",
            "Batch: 200 || Train Loss: 0.095 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.111 s\n",
            "Batch: 210 || Train Loss: 0.13 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.144 s\n",
            "Batch: 220 || Train Loss: 0.086 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.18 s\n",
            "Batch: 230 || Train Loss: 0.374 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.214 s\n",
            "Batch: 240 || Train Loss: 0.177 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.248 s\n",
            "Batch: 250 || Train Loss: 0.295 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.282 s\n",
            "Batch: 260 || Train Loss: 0.24 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.319 s\n",
            "Batch: 270 || Train Loss: 0.129 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.353 s\n",
            "Batch: 280 || Train Loss: 0.111 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.39 s\n",
            "Batch: 290 || Train Loss: 0.242 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.424 s\n",
            "Batch: 300 || Train Loss: 0.18 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.458 s\n",
            "Batch: 310 || Train Loss: 0.198 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.492 s\n",
            "Batch: 320 || Train Loss: 0.116 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.529 s\n",
            "Batch: 330 || Train Loss: 0.119 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.565 s\n",
            "Batch: 340 || Train Loss: 0.123 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.602 s\n",
            "Batch: 350 || Train Loss: 0.107 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.636 s\n",
            "Batch: 360 || Train Loss: 0.058 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.67 s\n",
            "Batch: 370 || Train Loss: 0.401 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.703 s\n",
            "Batch: 380 || Train Loss: 0.108 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.739 s\n",
            "Batch: 390 || Train Loss: 0.123 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.779 s\n",
            "Batch: 400 || Train Loss: 0.206 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.819 s\n",
            "Batch: 410 || Train Loss: 0.177 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028] || Time: 8.855 s\n",
            "Epoch: 7\n",
            "Batch: 10 || Train Loss: 0.198 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 8.903 s\n",
            "Batch: 20 || Train Loss: 0.06 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 8.937 s\n",
            "Batch: 30 || Train Loss: 0.111 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 8.973 s\n",
            "Batch: 40 || Train Loss: 0.178 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.008 s\n",
            "Batch: 50 || Train Loss: 0.079 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.046 s\n",
            "Batch: 60 || Train Loss: 0.198 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.08 s\n",
            "Batch: 70 || Train Loss: 0.029 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.115 s\n",
            "Batch: 80 || Train Loss: 0.203 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.151 s\n",
            "Batch: 90 || Train Loss: 0.161 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.185 s\n",
            "Batch: 100 || Train Loss: 0.19 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.22 s\n",
            "Batch: 110 || Train Loss: 0.134 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.26 s\n",
            "Batch: 120 || Train Loss: 0.064 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.294 s\n",
            "Batch: 130 || Train Loss: 0.125 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.328 s\n",
            "Batch: 140 || Train Loss: 0.171 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.365 s\n",
            "Batch: 150 || Train Loss: 0.059 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.4 s\n",
            "Batch: 160 || Train Loss: 0.109 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.434 s\n",
            "Batch: 170 || Train Loss: 0.131 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.472 s\n",
            "Batch: 180 || Train Loss: 0.125 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.506 s\n",
            "Batch: 190 || Train Loss: 0.086 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.542 s\n",
            "Batch: 200 || Train Loss: 0.051 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.576 s\n",
            "Batch: 210 || Train Loss: 0.102 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.613 s\n",
            "Batch: 220 || Train Loss: 0.254 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.647 s\n",
            "Batch: 230 || Train Loss: 0.098 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.684 s\n",
            "Batch: 240 || Train Loss: 0.171 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.718 s\n",
            "Batch: 250 || Train Loss: 0.193 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.752 s\n",
            "Batch: 260 || Train Loss: 0.094 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.786 s\n",
            "Batch: 270 || Train Loss: 0.071 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.824 s\n",
            "Batch: 280 || Train Loss: 0.145 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.862 s\n",
            "Batch: 290 || Train Loss: 0.134 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.902 s\n",
            "Batch: 300 || Train Loss: 0.147 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.938 s\n",
            "Batch: 310 || Train Loss: 0.211 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 9.973 s\n",
            "Batch: 320 || Train Loss: 0.166 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 10.009 s\n",
            "Batch: 330 || Train Loss: 0.213 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 10.043 s\n",
            "Batch: 340 || Train Loss: 0.156 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 10.081 s\n",
            "Batch: 350 || Train Loss: 0.044 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 10.118 s\n",
            "Batch: 360 || Train Loss: 0.083 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 10.156 s\n",
            "Batch: 370 || Train Loss: 0.126 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 10.191 s\n",
            "Batch: 380 || Train Loss: 0.131 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 10.232 s\n",
            "Batch: 390 || Train Loss: 0.173 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 10.269 s\n",
            "Batch: 400 || Train Loss: 0.133 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 10.304 s\n",
            "Batch: 410 || Train Loss: 0.022 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768] || Time: 10.341 s\n",
            "Epoch: 8\n",
            "Batch: 10 || Train Loss: 0.118 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.39 s\n",
            "Batch: 20 || Train Loss: 0.239 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.424 s\n",
            "Batch: 30 || Train Loss: 0.018 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.458 s\n",
            "Batch: 40 || Train Loss: 0.386 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.492 s\n",
            "Batch: 50 || Train Loss: 0.1 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.53 s\n",
            "Batch: 60 || Train Loss: 0.059 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.567 s\n",
            "Batch: 70 || Train Loss: 0.062 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.601 s\n",
            "Batch: 80 || Train Loss: 0.106 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.634 s\n",
            "Batch: 90 || Train Loss: 0.054 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.668 s\n",
            "Batch: 100 || Train Loss: 0.051 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.702 s\n",
            "Batch: 110 || Train Loss: 0.158 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.741 s\n",
            "Batch: 120 || Train Loss: 0.259 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.778 s\n",
            "Batch: 130 || Train Loss: 0.018 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.817 s\n",
            "Batch: 140 || Train Loss: 0.093 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.851 s\n",
            "Batch: 150 || Train Loss: 0.095 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.884 s\n",
            "Batch: 160 || Train Loss: 0.061 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.918 s\n",
            "Batch: 170 || Train Loss: 0.143 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.954 s\n",
            "Batch: 180 || Train Loss: 0.203 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 10.992 s\n",
            "Batch: 190 || Train Loss: 0.244 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.026 s\n",
            "Batch: 200 || Train Loss: 0.204 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.059 s\n",
            "Batch: 210 || Train Loss: 0.194 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.093 s\n",
            "Batch: 220 || Train Loss: 0.208 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.126 s\n",
            "Batch: 230 || Train Loss: 0.045 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.163 s\n",
            "Batch: 240 || Train Loss: 0.233 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.2 s\n",
            "Batch: 250 || Train Loss: 0.077 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.236 s\n",
            "Batch: 260 || Train Loss: 0.029 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.273 s\n",
            "Batch: 270 || Train Loss: 0.206 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.309 s\n",
            "Batch: 280 || Train Loss: 0.206 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.344 s\n",
            "Batch: 290 || Train Loss: 0.048 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.381 s\n",
            "Batch: 300 || Train Loss: 0.438 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.419 s\n",
            "Batch: 310 || Train Loss: 0.153 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.453 s\n",
            "Batch: 320 || Train Loss: 0.206 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.488 s\n",
            "Batch: 330 || Train Loss: 0.245 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.523 s\n",
            "Batch: 340 || Train Loss: 0.057 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.558 s\n",
            "Batch: 350 || Train Loss: 0.218 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.595 s\n",
            "Batch: 360 || Train Loss: 0.315 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.636 s\n",
            "Batch: 370 || Train Loss: 0.097 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.672 s\n",
            "Batch: 380 || Train Loss: 0.183 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.706 s\n",
            "Batch: 390 || Train Loss: 0.146 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.741 s\n",
            "Batch: 400 || Train Loss: 0.126 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.777 s\n",
            "Batch: 410 || Train Loss: 0.091 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131] || Time: 11.812 s\n",
            "Epoch: 9\n",
            "Batch: 10 || Train Loss: 0.074 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 11.868 s\n",
            "Batch: 20 || Train Loss: 0.193 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 11.902 s\n",
            "Batch: 30 || Train Loss: 0.126 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 11.935 s\n",
            "Batch: 40 || Train Loss: 0.183 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 11.97 s\n",
            "Batch: 50 || Train Loss: 0.142 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.01 s\n",
            "Batch: 60 || Train Loss: 0.148 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.044 s\n",
            "Batch: 70 || Train Loss: 0.107 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.082 s\n",
            "Batch: 80 || Train Loss: 0.18 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.115 s\n",
            "Batch: 90 || Train Loss: 0.096 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.149 s\n",
            "Batch: 100 || Train Loss: 0.172 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.182 s\n",
            "Batch: 110 || Train Loss: 0.091 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.216 s\n",
            "Batch: 120 || Train Loss: 0.094 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.252 s\n",
            "Batch: 130 || Train Loss: 0.071 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.292 s\n",
            "Batch: 140 || Train Loss: 0.054 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.327 s\n",
            "Batch: 150 || Train Loss: 0.016 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.362 s\n",
            "Batch: 160 || Train Loss: 0.188 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.396 s\n",
            "Batch: 170 || Train Loss: 0.113 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.431 s\n",
            "Batch: 180 || Train Loss: 0.119 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.467 s\n",
            "Batch: 190 || Train Loss: 0.068 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.505 s\n",
            "Batch: 200 || Train Loss: 0.029 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.54 s\n",
            "Batch: 210 || Train Loss: 0.097 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.574 s\n",
            "Batch: 220 || Train Loss: 0.125 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.608 s\n",
            "Batch: 230 || Train Loss: 0.116 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.641 s\n",
            "Batch: 240 || Train Loss: 0.204 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.677 s\n",
            "Batch: 250 || Train Loss: 0.034 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.715 s\n",
            "Batch: 260 || Train Loss: 0.156 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.749 s\n",
            "Batch: 270 || Train Loss: 0.383 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.783 s\n",
            "Batch: 280 || Train Loss: 0.109 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.822 s\n",
            "Batch: 290 || Train Loss: 0.027 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.861 s\n",
            "Batch: 300 || Train Loss: 0.184 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.898 s\n",
            "Batch: 310 || Train Loss: 0.088 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.937 s\n",
            "Batch: 320 || Train Loss: 0.126 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 12.971 s\n",
            "Batch: 330 || Train Loss: 0.1 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 13.006 s\n",
            "Batch: 340 || Train Loss: 0.112 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 13.041 s\n",
            "Batch: 350 || Train Loss: 0.091 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 13.075 s\n",
            "Batch: 360 || Train Loss: 0.128 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 13.112 s\n",
            "Batch: 370 || Train Loss: 0.02 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 13.149 s\n",
            "Batch: 380 || Train Loss: 0.23 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 13.183 s\n",
            "Batch: 390 || Train Loss: 0.033 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 13.218 s\n",
            "Batch: 400 || Train Loss: 0.126 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 13.253 s\n",
            "Batch: 410 || Train Loss: 0.103 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627] || Time: 13.288 s\n",
            "Epoch: 10\n",
            "Batch: 10 || Train Loss: 0.112 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.339 s\n",
            "Batch: 20 || Train Loss: 0.044 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.376 s\n",
            "Batch: 30 || Train Loss: 0.107 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.41 s\n",
            "Batch: 40 || Train Loss: 0.091 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.444 s\n",
            "Batch: 50 || Train Loss: 0.106 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.48 s\n",
            "Batch: 60 || Train Loss: 0.091 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.525 s\n",
            "Batch: 70 || Train Loss: 0.035 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.566 s\n",
            "Batch: 80 || Train Loss: 0.115 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.605 s\n",
            "Batch: 90 || Train Loss: 0.038 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.642 s\n",
            "Batch: 100 || Train Loss: 0.108 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.676 s\n",
            "Batch: 110 || Train Loss: 0.093 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.713 s\n",
            "Batch: 120 || Train Loss: 0.221 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.748 s\n",
            "Batch: 130 || Train Loss: 0.051 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.783 s\n",
            "Batch: 140 || Train Loss: 0.072 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.82 s\n",
            "Batch: 150 || Train Loss: 0.16 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.859 s\n",
            "Batch: 160 || Train Loss: 0.065 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.893 s\n",
            "Batch: 170 || Train Loss: 0.16 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.931 s\n",
            "Batch: 180 || Train Loss: 0.098 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.964 s\n",
            "Batch: 190 || Train Loss: 0.051 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 13.999 s\n",
            "Batch: 200 || Train Loss: 0.05 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.037 s\n",
            "Batch: 210 || Train Loss: 0.128 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.071 s\n",
            "Batch: 220 || Train Loss: 0.045 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.105 s\n",
            "Batch: 230 || Train Loss: 0.044 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.14 s\n",
            "Batch: 240 || Train Loss: 0.154 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.176 s\n",
            "Batch: 250 || Train Loss: 0.066 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.21 s\n",
            "Batch: 260 || Train Loss: 0.01 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.248 s\n",
            "Batch: 270 || Train Loss: 0.068 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.282 s\n",
            "Batch: 280 || Train Loss: 0.125 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.316 s\n",
            "Batch: 290 || Train Loss: 0.141 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.352 s\n",
            "Batch: 300 || Train Loss: 0.045 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.386 s\n",
            "Batch: 310 || Train Loss: 0.045 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.421 s\n",
            "Batch: 320 || Train Loss: 0.102 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.46 s\n",
            "Batch: 330 || Train Loss: 0.074 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.495 s\n",
            "Batch: 340 || Train Loss: 0.133 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.531 s\n",
            "Batch: 350 || Train Loss: 0.31 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.568 s\n",
            "Batch: 360 || Train Loss: 0.038 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.602 s\n",
            "Batch: 370 || Train Loss: 0.084 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.635 s\n",
            "Batch: 380 || Train Loss: 0.134 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.673 s\n",
            "Batch: 390 || Train Loss: 0.387 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.707 s\n",
            "Batch: 400 || Train Loss: 0.107 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.74 s\n",
            "Batch: 410 || Train Loss: 0.143 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173] || Time: 14.777 s\n",
            "Epoch: 11\n",
            "Batch: 10 || Train Loss: 0.049 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 14.826 s\n",
            "Batch: 20 || Train Loss: 0.081 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 14.864 s\n",
            "Batch: 30 || Train Loss: 0.053 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 14.901 s\n",
            "Batch: 40 || Train Loss: 0.082 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 14.935 s\n",
            "Batch: 50 || Train Loss: 0.08 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 14.968 s\n",
            "Batch: 60 || Train Loss: 0.203 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.01 s\n",
            "Batch: 70 || Train Loss: 0.054 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.047 s\n",
            "Batch: 80 || Train Loss: 0.044 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.082 s\n",
            "Batch: 90 || Train Loss: 0.038 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.12 s\n",
            "Batch: 100 || Train Loss: 0.054 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.154 s\n",
            "Batch: 110 || Train Loss: 0.019 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.189 s\n",
            "Batch: 120 || Train Loss: 0.137 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.225 s\n",
            "Batch: 130 || Train Loss: 0.097 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.259 s\n",
            "Batch: 140 || Train Loss: 0.038 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.293 s\n",
            "Batch: 150 || Train Loss: 0.101 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.331 s\n",
            "Batch: 160 || Train Loss: 0.07 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.365 s\n",
            "Batch: 170 || Train Loss: 0.184 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.399 s\n",
            "Batch: 180 || Train Loss: 0.052 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.437 s\n",
            "Batch: 190 || Train Loss: 0.166 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.471 s\n",
            "Batch: 200 || Train Loss: 0.198 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.507 s\n",
            "Batch: 210 || Train Loss: 0.231 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.545 s\n",
            "Batch: 220 || Train Loss: 0.195 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.594 s\n",
            "Batch: 230 || Train Loss: 0.103 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.63 s\n",
            "Batch: 240 || Train Loss: 0.061 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.666 s\n",
            "Batch: 250 || Train Loss: 0.1 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.7 s\n",
            "Batch: 260 || Train Loss: 0.047 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.734 s\n",
            "Batch: 270 || Train Loss: 0.073 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.774 s\n",
            "Batch: 280 || Train Loss: 0.069 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.809 s\n",
            "Batch: 290 || Train Loss: 0.187 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.847 s\n",
            "Batch: 300 || Train Loss: 0.053 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.887 s\n",
            "Batch: 310 || Train Loss: 0.211 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.92 s\n",
            "Batch: 320 || Train Loss: 0.063 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.954 s\n",
            "Batch: 330 || Train Loss: 0.104 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 15.992 s\n",
            "Batch: 340 || Train Loss: 0.184 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 16.028 s\n",
            "Batch: 350 || Train Loss: 0.305 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 16.064 s\n",
            "Batch: 360 || Train Loss: 0.14 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 16.109 s\n",
            "Batch: 370 || Train Loss: 0.168 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 16.141 s\n",
            "Batch: 380 || Train Loss: 0.149 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 16.179 s\n",
            "Batch: 390 || Train Loss: 0.057 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 16.218 s\n",
            "Batch: 400 || Train Loss: 0.075 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 16.253 s\n",
            "Batch: 410 || Train Loss: 0.064 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497] || Time: 16.286 s\n",
            "Epoch: 12\n",
            "Batch: 10 || Train Loss: 0.082 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.337 s\n",
            "Batch: 20 || Train Loss: 0.145 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.371 s\n",
            "Batch: 30 || Train Loss: 0.11 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.404 s\n",
            "Batch: 40 || Train Loss: 0.103 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.441 s\n",
            "Batch: 50 || Train Loss: 0.029 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.475 s\n",
            "Batch: 60 || Train Loss: 0.032 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.509 s\n",
            "Batch: 70 || Train Loss: 0.283 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.545 s\n",
            "Batch: 80 || Train Loss: 0.057 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.578 s\n",
            "Batch: 90 || Train Loss: 0.082 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.612 s\n",
            "Batch: 100 || Train Loss: 0.127 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.648 s\n",
            "Batch: 110 || Train Loss: 0.132 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.682 s\n",
            "Batch: 120 || Train Loss: 0.061 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.715 s\n",
            "Batch: 130 || Train Loss: 0.093 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.752 s\n",
            "Batch: 140 || Train Loss: 0.111 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.785 s\n",
            "Batch: 150 || Train Loss: 0.092 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.818 s\n",
            "Batch: 160 || Train Loss: 0.021 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.856 s\n",
            "Batch: 170 || Train Loss: 0.199 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.894 s\n",
            "Batch: 180 || Train Loss: 0.056 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.927 s\n",
            "Batch: 190 || Train Loss: 0.059 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.963 s\n",
            "Batch: 200 || Train Loss: 0.243 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 16.996 s\n",
            "Batch: 210 || Train Loss: 0.052 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.031 s\n",
            "Batch: 220 || Train Loss: 0.231 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.068 s\n",
            "Batch: 230 || Train Loss: 0.343 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.102 s\n",
            "Batch: 240 || Train Loss: 0.284 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.136 s\n",
            "Batch: 250 || Train Loss: 0.153 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.173 s\n",
            "Batch: 260 || Train Loss: 0.055 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.206 s\n",
            "Batch: 270 || Train Loss: 0.026 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.241 s\n",
            "Batch: 280 || Train Loss: 0.059 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.28 s\n",
            "Batch: 290 || Train Loss: 0.129 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.315 s\n",
            "Batch: 300 || Train Loss: 0.056 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.35 s\n",
            "Batch: 310 || Train Loss: 0.1 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.392 s\n",
            "Batch: 320 || Train Loss: 0.048 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.428 s\n",
            "Batch: 330 || Train Loss: 0.041 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.462 s\n",
            "Batch: 340 || Train Loss: 0.075 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.5 s\n",
            "Batch: 350 || Train Loss: 0.103 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.534 s\n",
            "Batch: 360 || Train Loss: 0.138 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.568 s\n",
            "Batch: 370 || Train Loss: 0.181 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.605 s\n",
            "Batch: 380 || Train Loss: 0.241 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.638 s\n",
            "Batch: 390 || Train Loss: 0.179 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.672 s\n",
            "Batch: 400 || Train Loss: 0.046 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.709 s\n",
            "Batch: 410 || Train Loss: 0.093 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372] || Time: 17.743 s\n",
            "Epoch: 13\n",
            "Batch: 10 || Train Loss: 0.025 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 17.79 s\n",
            "Batch: 20 || Train Loss: 0.031 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 17.826 s\n",
            "Batch: 30 || Train Loss: 0.059 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 17.86 s\n",
            "Batch: 40 || Train Loss: 0.15 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 17.897 s\n",
            "Batch: 50 || Train Loss: 0.19 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 17.935 s\n",
            "Batch: 60 || Train Loss: 0.1 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 17.969 s\n",
            "Batch: 70 || Train Loss: 0.12 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.003 s\n",
            "Batch: 80 || Train Loss: 0.127 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.036 s\n",
            "Batch: 90 || Train Loss: 0.04 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.071 s\n",
            "Batch: 100 || Train Loss: 0.051 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.105 s\n",
            "Batch: 110 || Train Loss: 0.172 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.145 s\n",
            "Batch: 120 || Train Loss: 0.206 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.18 s\n",
            "Batch: 130 || Train Loss: 0.085 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.213 s\n",
            "Batch: 140 || Train Loss: 0.065 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.247 s\n",
            "Batch: 150 || Train Loss: 0.092 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.281 s\n",
            "Batch: 160 || Train Loss: 0.212 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.315 s\n",
            "Batch: 170 || Train Loss: 0.087 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.357 s\n",
            "Batch: 180 || Train Loss: 0.153 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.391 s\n",
            "Batch: 190 || Train Loss: 0.148 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.429 s\n",
            "Batch: 200 || Train Loss: 0.078 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.463 s\n",
            "Batch: 210 || Train Loss: 0.054 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.497 s\n",
            "Batch: 220 || Train Loss: 0.068 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.532 s\n",
            "Batch: 230 || Train Loss: 0.266 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.572 s\n",
            "Batch: 240 || Train Loss: 0.053 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.607 s\n",
            "Batch: 250 || Train Loss: 0.054 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.642 s\n",
            "Batch: 260 || Train Loss: 0.155 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.677 s\n",
            "Batch: 270 || Train Loss: 0.135 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.712 s\n",
            "Batch: 280 || Train Loss: 0.152 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.746 s\n",
            "Batch: 290 || Train Loss: 0.133 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.784 s\n",
            "Batch: 300 || Train Loss: 0.127 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.819 s\n",
            "Batch: 310 || Train Loss: 0.031 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.853 s\n",
            "Batch: 320 || Train Loss: 0.298 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.887 s\n",
            "Batch: 330 || Train Loss: 0.035 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.93 s\n",
            "Batch: 340 || Train Loss: 0.049 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 18.964 s\n",
            "Batch: 350 || Train Loss: 0.052 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 19.004 s\n",
            "Batch: 360 || Train Loss: 0.164 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 19.038 s\n",
            "Batch: 370 || Train Loss: 0.014 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 19.072 s\n",
            "Batch: 380 || Train Loss: 0.139 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 19.105 s\n",
            "Batch: 390 || Train Loss: 0.053 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 19.141 s\n",
            "Batch: 400 || Train Loss: 0.062 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 19.175 s\n",
            "Batch: 410 || Train Loss: 0.193 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019] || Time: 19.213 s\n",
            "Epoch: 14\n",
            "Batch: 10 || Train Loss: 0.018 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.261 s\n",
            "Batch: 20 || Train Loss: 0.079 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.294 s\n",
            "Batch: 30 || Train Loss: 0.02 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.328 s\n",
            "Batch: 40 || Train Loss: 0.021 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.364 s\n",
            "Batch: 50 || Train Loss: 0.072 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.398 s\n",
            "Batch: 60 || Train Loss: 0.181 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.435 s\n",
            "Batch: 70 || Train Loss: 0.181 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.469 s\n",
            "Batch: 80 || Train Loss: 0.088 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.502 s\n",
            "Batch: 90 || Train Loss: 0.104 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.536 s\n",
            "Batch: 100 || Train Loss: 0.024 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.572 s\n",
            "Batch: 110 || Train Loss: 0.127 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.605 s\n",
            "Batch: 120 || Train Loss: 0.146 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.644 s\n",
            "Batch: 130 || Train Loss: 0.06 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.68 s\n",
            "Batch: 140 || Train Loss: 0.074 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.716 s\n",
            "Batch: 150 || Train Loss: 0.22 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.75 s\n",
            "Batch: 160 || Train Loss: 0.221 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.788 s\n",
            "Batch: 170 || Train Loss: 0.029 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.823 s\n",
            "Batch: 180 || Train Loss: 0.081 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.86 s\n",
            "Batch: 190 || Train Loss: 0.112 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.895 s\n",
            "Batch: 200 || Train Loss: 0.093 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.935 s\n",
            "Batch: 210 || Train Loss: 0.093 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 19.969 s\n",
            "Batch: 220 || Train Loss: 0.115 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.006 s\n",
            "Batch: 230 || Train Loss: 0.055 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.04 s\n",
            "Batch: 240 || Train Loss: 0.111 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.079 s\n",
            "Batch: 250 || Train Loss: 0.102 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.113 s\n",
            "Batch: 260 || Train Loss: 0.065 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.146 s\n",
            "Batch: 270 || Train Loss: 0.022 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.18 s\n",
            "Batch: 280 || Train Loss: 0.076 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.213 s\n",
            "Batch: 290 || Train Loss: 0.144 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.247 s\n",
            "Batch: 300 || Train Loss: 0.289 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.281 s\n",
            "Batch: 310 || Train Loss: 0.087 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.316 s\n",
            "Batch: 320 || Train Loss: 0.085 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.349 s\n",
            "Batch: 330 || Train Loss: 0.316 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.382 s\n",
            "Batch: 340 || Train Loss: 0.028 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.416 s\n",
            "Batch: 350 || Train Loss: 0.05 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.45 s\n",
            "Batch: 360 || Train Loss: 0.145 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.492 s\n",
            "Batch: 370 || Train Loss: 0.027 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.532 s\n",
            "Batch: 380 || Train Loss: 0.101 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.568 s\n",
            "Batch: 390 || Train Loss: 0.026 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.603 s\n",
            "Batch: 400 || Train Loss: 0.108 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.638 s\n",
            "Batch: 410 || Train Loss: 0.048 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197] || Time: 20.671 s\n",
            "Epoch: 15\n",
            "Batch: 10 || Train Loss: 0.119 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 20.724 s\n",
            "Batch: 20 || Train Loss: 0.054 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 20.758 s\n",
            "Batch: 30 || Train Loss: 0.215 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 20.791 s\n",
            "Batch: 40 || Train Loss: 0.156 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 20.825 s\n",
            "Batch: 50 || Train Loss: 0.058 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 20.858 s\n",
            "Batch: 60 || Train Loss: 0.055 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 20.892 s\n",
            "Batch: 70 || Train Loss: 0.155 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 20.938 s\n",
            "Batch: 80 || Train Loss: 0.156 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 20.973 s\n",
            "Batch: 90 || Train Loss: 0.139 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.011 s\n",
            "Batch: 100 || Train Loss: 0.24 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.048 s\n",
            "Batch: 110 || Train Loss: 0.117 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.085 s\n",
            "Batch: 120 || Train Loss: 0.046 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.122 s\n",
            "Batch: 130 || Train Loss: 0.029 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.163 s\n",
            "Batch: 140 || Train Loss: 0.04 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.198 s\n",
            "Batch: 150 || Train Loss: 0.091 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.233 s\n",
            "Batch: 160 || Train Loss: 0.121 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.267 s\n",
            "Batch: 170 || Train Loss: 0.053 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.307 s\n",
            "Batch: 180 || Train Loss: 0.174 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.341 s\n",
            "Batch: 190 || Train Loss: 0.091 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.383 s\n",
            "Batch: 200 || Train Loss: 0.096 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.419 s\n",
            "Batch: 210 || Train Loss: 0.153 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.454 s\n",
            "Batch: 220 || Train Loss: 0.243 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.489 s\n",
            "Batch: 230 || Train Loss: 0.084 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.524 s\n",
            "Batch: 240 || Train Loss: 0.016 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.558 s\n",
            "Batch: 250 || Train Loss: 0.07 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.596 s\n",
            "Batch: 260 || Train Loss: 0.116 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.63 s\n",
            "Batch: 270 || Train Loss: 0.213 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.663 s\n",
            "Batch: 280 || Train Loss: 0.051 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.696 s\n",
            "Batch: 290 || Train Loss: 0.15 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.733 s\n",
            "Batch: 300 || Train Loss: 0.077 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.767 s\n",
            "Batch: 310 || Train Loss: 0.059 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.804 s\n",
            "Batch: 320 || Train Loss: 0.123 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.837 s\n",
            "Batch: 330 || Train Loss: 0.032 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.87 s\n",
            "Batch: 340 || Train Loss: 0.112 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.904 s\n",
            "Batch: 350 || Train Loss: 0.112 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.938 s\n",
            "Batch: 360 || Train Loss: 0.051 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 21.976 s\n",
            "Batch: 370 || Train Loss: 0.066 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 22.021 s\n",
            "Batch: 380 || Train Loss: 0.097 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 22.056 s\n",
            "Batch: 390 || Train Loss: 0.095 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 22.091 s\n",
            "Batch: 400 || Train Loss: 0.043 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 22.124 s\n",
            "Batch: 410 || Train Loss: 0.1 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312] || Time: 22.158 s\n",
            "Epoch: 16\n",
            "Batch: 10 || Train Loss: 0.077 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.206 s\n",
            "Batch: 20 || Train Loss: 0.041 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.249 s\n",
            "Batch: 30 || Train Loss: 0.093 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.287 s\n",
            "Batch: 40 || Train Loss: 0.167 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.322 s\n",
            "Batch: 50 || Train Loss: 0.074 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.356 s\n",
            "Batch: 60 || Train Loss: 0.229 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.39 s\n",
            "Batch: 70 || Train Loss: 0.082 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.424 s\n",
            "Batch: 80 || Train Loss: 0.034 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.462 s\n",
            "Batch: 90 || Train Loss: 0.04 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.498 s\n",
            "Batch: 100 || Train Loss: 0.076 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.531 s\n",
            "Batch: 110 || Train Loss: 0.13 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.565 s\n",
            "Batch: 120 || Train Loss: 0.031 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.598 s\n",
            "Batch: 130 || Train Loss: 0.042 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.631 s\n",
            "Batch: 140 || Train Loss: 0.074 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.667 s\n",
            "Batch: 150 || Train Loss: 0.19 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.701 s\n",
            "Batch: 160 || Train Loss: 0.126 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.734 s\n",
            "Batch: 170 || Train Loss: 0.018 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.77 s\n",
            "Batch: 180 || Train Loss: 0.074 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.803 s\n",
            "Batch: 190 || Train Loss: 0.044 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.837 s\n",
            "Batch: 200 || Train Loss: 0.042 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.872 s\n",
            "Batch: 210 || Train Loss: 0.115 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.907 s\n",
            "Batch: 220 || Train Loss: 0.019 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.941 s\n",
            "Batch: 230 || Train Loss: 0.04 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 22.98 s\n",
            "Batch: 240 || Train Loss: 0.078 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.017 s\n",
            "Batch: 250 || Train Loss: 0.1 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.052 s\n",
            "Batch: 260 || Train Loss: 0.039 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.093 s\n",
            "Batch: 270 || Train Loss: 0.105 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.128 s\n",
            "Batch: 280 || Train Loss: 0.085 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.163 s\n",
            "Batch: 290 || Train Loss: 0.057 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.201 s\n",
            "Batch: 300 || Train Loss: 0.159 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.238 s\n",
            "Batch: 310 || Train Loss: 0.057 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.273 s\n",
            "Batch: 320 || Train Loss: 0.064 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.311 s\n",
            "Batch: 330 || Train Loss: 0.103 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.345 s\n",
            "Batch: 340 || Train Loss: 0.225 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.379 s\n",
            "Batch: 350 || Train Loss: 0.035 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.418 s\n",
            "Batch: 360 || Train Loss: 0.071 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.452 s\n",
            "Batch: 370 || Train Loss: 0.117 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.489 s\n",
            "Batch: 380 || Train Loss: 0.094 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.53 s\n",
            "Batch: 390 || Train Loss: 0.063 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.566 s\n",
            "Batch: 400 || Train Loss: 0.169 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.6 s\n",
            "Batch: 410 || Train Loss: 0.103 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777] || Time: 23.634 s\n",
            "Epoch: 17\n",
            "Batch: 10 || Train Loss: 0.028 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 23.682 s\n",
            "Batch: 20 || Train Loss: 0.085 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 23.717 s\n",
            "Batch: 30 || Train Loss: 0.053 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 23.757 s\n",
            "Batch: 40 || Train Loss: 0.089 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 23.79 s\n",
            "Batch: 50 || Train Loss: 0.061 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 23.823 s\n",
            "Batch: 60 || Train Loss: 0.049 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 23.856 s\n",
            "Batch: 70 || Train Loss: 0.078 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 23.893 s\n",
            "Batch: 80 || Train Loss: 0.051 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 23.932 s\n",
            "Batch: 90 || Train Loss: 0.106 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 23.98 s\n",
            "Batch: 100 || Train Loss: 0.088 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.016 s\n",
            "Batch: 110 || Train Loss: 0.128 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.05 s\n",
            "Batch: 120 || Train Loss: 0.046 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.084 s\n",
            "Batch: 130 || Train Loss: 0.014 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.118 s\n",
            "Batch: 140 || Train Loss: 0.043 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.15 s\n",
            "Batch: 150 || Train Loss: 0.118 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.187 s\n",
            "Batch: 160 || Train Loss: 0.014 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.222 s\n",
            "Batch: 170 || Train Loss: 0.013 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.256 s\n",
            "Batch: 180 || Train Loss: 0.016 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.29 s\n",
            "Batch: 190 || Train Loss: 0.123 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.324 s\n",
            "Batch: 200 || Train Loss: 0.074 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.357 s\n",
            "Batch: 210 || Train Loss: 0.036 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.396 s\n",
            "Batch: 220 || Train Loss: 0.301 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.43 s\n",
            "Batch: 230 || Train Loss: 0.192 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.464 s\n",
            "Batch: 240 || Train Loss: 0.047 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.498 s\n",
            "Batch: 250 || Train Loss: 0.034 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.531 s\n",
            "Batch: 260 || Train Loss: 0.204 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.566 s\n",
            "Batch: 270 || Train Loss: 0.05 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.606 s\n",
            "Batch: 280 || Train Loss: 0.136 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.641 s\n",
            "Batch: 290 || Train Loss: 0.01 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.68 s\n",
            "Batch: 300 || Train Loss: 0.278 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.715 s\n",
            "Batch: 310 || Train Loss: 0.019 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.75 s\n",
            "Batch: 320 || Train Loss: 0.061 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.784 s\n",
            "Batch: 330 || Train Loss: 0.127 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.822 s\n",
            "Batch: 340 || Train Loss: 0.099 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.856 s\n",
            "Batch: 350 || Train Loss: 0.037 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.89 s\n",
            "Batch: 360 || Train Loss: 0.146 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.923 s\n",
            "Batch: 370 || Train Loss: 0.084 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.957 s\n",
            "Batch: 380 || Train Loss: 0.069 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 24.996 s\n",
            "Batch: 390 || Train Loss: 0.081 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 25.035 s\n",
            "Batch: 400 || Train Loss: 0.22 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 25.071 s\n",
            "Batch: 410 || Train Loss: 0.216 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597] || Time: 25.115 s\n",
            "Epoch: 18\n",
            "Batch: 10 || Train Loss: 0.234 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.165 s\n",
            "Batch: 20 || Train Loss: 0.021 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.2 s\n",
            "Batch: 30 || Train Loss: 0.034 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.234 s\n",
            "Batch: 40 || Train Loss: 0.051 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.275 s\n",
            "Batch: 50 || Train Loss: 0.111 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.31 s\n",
            "Batch: 60 || Train Loss: 0.186 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.355 s\n",
            "Batch: 70 || Train Loss: 0.117 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.39 s\n",
            "Batch: 80 || Train Loss: 0.136 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.425 s\n",
            "Batch: 90 || Train Loss: 0.047 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.459 s\n",
            "Batch: 100 || Train Loss: 0.169 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.497 s\n",
            "Batch: 110 || Train Loss: 0.095 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.531 s\n",
            "Batch: 120 || Train Loss: 0.011 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.565 s\n",
            "Batch: 130 || Train Loss: 0.053 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.598 s\n",
            "Batch: 140 || Train Loss: 0.049 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.631 s\n",
            "Batch: 150 || Train Loss: 0.061 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.664 s\n",
            "Batch: 160 || Train Loss: 0.053 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.697 s\n",
            "Batch: 170 || Train Loss: 0.073 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.739 s\n",
            "Batch: 180 || Train Loss: 0.015 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.774 s\n",
            "Batch: 190 || Train Loss: 0.061 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.809 s\n",
            "Batch: 200 || Train Loss: 0.017 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.844 s\n",
            "Batch: 210 || Train Loss: 0.009 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.878 s\n",
            "Batch: 220 || Train Loss: 0.104 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.912 s\n",
            "Batch: 230 || Train Loss: 0.068 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.949 s\n",
            "Batch: 240 || Train Loss: 0.101 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 25.987 s\n",
            "Batch: 250 || Train Loss: 0.109 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.025 s\n",
            "Batch: 260 || Train Loss: 0.058 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.059 s\n",
            "Batch: 270 || Train Loss: 0.017 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.093 s\n",
            "Batch: 280 || Train Loss: 0.01 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.126 s\n",
            "Batch: 290 || Train Loss: 0.176 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.165 s\n",
            "Batch: 300 || Train Loss: 0.126 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.203 s\n",
            "Batch: 310 || Train Loss: 0.022 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.238 s\n",
            "Batch: 320 || Train Loss: 0.049 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.274 s\n",
            "Batch: 330 || Train Loss: 0.102 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.308 s\n",
            "Batch: 340 || Train Loss: 0.061 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.341 s\n",
            "Batch: 350 || Train Loss: 0.177 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.38 s\n",
            "Batch: 360 || Train Loss: 0.053 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.415 s\n",
            "Batch: 370 || Train Loss: 0.038 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.453 s\n",
            "Batch: 380 || Train Loss: 0.146 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.488 s\n",
            "Batch: 390 || Train Loss: 0.115 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.523 s\n",
            "Batch: 400 || Train Loss: 0.153 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.556 s\n",
            "Batch: 410 || Train Loss: 0.023 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647] || Time: 26.595 s\n",
            "Epoch: 19\n",
            "Batch: 10 || Train Loss: 0.174 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 26.643 s\n",
            "Batch: 20 || Train Loss: 0.015 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 26.678 s\n",
            "Batch: 30 || Train Loss: 0.038 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 26.714 s\n",
            "Batch: 40 || Train Loss: 0.122 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 26.747 s\n",
            "Batch: 50 || Train Loss: 0.068 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 26.781 s\n",
            "Batch: 60 || Train Loss: 0.035 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 26.821 s\n",
            "Batch: 70 || Train Loss: 0.043 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 26.855 s\n",
            "Batch: 80 || Train Loss: 0.036 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 26.89 s\n",
            "Batch: 90 || Train Loss: 0.034 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 26.928 s\n",
            "Batch: 100 || Train Loss: 0.073 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 26.963 s\n",
            "Batch: 110 || Train Loss: 0.123 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 26.998 s\n",
            "Batch: 120 || Train Loss: 0.018 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.042 s\n",
            "Batch: 130 || Train Loss: 0.14 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.077 s\n",
            "Batch: 140 || Train Loss: 0.096 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.112 s\n",
            "Batch: 150 || Train Loss: 0.356 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.145 s\n",
            "Batch: 160 || Train Loss: 0.085 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.18 s\n",
            "Batch: 170 || Train Loss: 0.083 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.215 s\n",
            "Batch: 180 || Train Loss: 0.117 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.255 s\n",
            "Batch: 190 || Train Loss: 0.044 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.289 s\n",
            "Batch: 200 || Train Loss: 0.037 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.323 s\n",
            "Batch: 210 || Train Loss: 0.066 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.356 s\n",
            "Batch: 220 || Train Loss: 0.161 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.389 s\n",
            "Batch: 230 || Train Loss: 0.13 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.426 s\n",
            "Batch: 240 || Train Loss: 0.108 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.467 s\n",
            "Batch: 250 || Train Loss: 0.015 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.502 s\n",
            "Batch: 260 || Train Loss: 0.053 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.54 s\n",
            "Batch: 270 || Train Loss: 0.023 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.577 s\n",
            "Batch: 280 || Train Loss: 0.134 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.611 s\n",
            "Batch: 290 || Train Loss: 0.083 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.645 s\n",
            "Batch: 300 || Train Loss: 0.126 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.685 s\n",
            "Batch: 310 || Train Loss: 0.043 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.723 s\n",
            "Batch: 320 || Train Loss: 0.055 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.758 s\n",
            "Batch: 330 || Train Loss: 0.064 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.793 s\n",
            "Batch: 340 || Train Loss: 0.117 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.827 s\n",
            "Batch: 350 || Train Loss: 0.077 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.861 s\n",
            "Batch: 360 || Train Loss: 0.096 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.899 s\n",
            "Batch: 370 || Train Loss: 0.095 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.936 s\n",
            "Batch: 380 || Train Loss: 0.124 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 27.971 s\n",
            "Batch: 390 || Train Loss: 0.095 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 28.006 s\n",
            "Batch: 400 || Train Loss: 0.177 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 28.047 s\n",
            "Batch: 410 || Train Loss: 0.115 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212] || Time: 28.08 s\n",
            "Epoch: 20\n",
            "Batch: 10 || Train Loss: 0.026 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.133 s\n",
            "Batch: 20 || Train Loss: 0.218 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.171 s\n",
            "Batch: 30 || Train Loss: 0.092 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.205 s\n",
            "Batch: 40 || Train Loss: 0.052 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.24 s\n",
            "Batch: 50 || Train Loss: 0.087 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.273 s\n",
            "Batch: 60 || Train Loss: 0.012 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.307 s\n",
            "Batch: 70 || Train Loss: 0.104 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.345 s\n",
            "Batch: 80 || Train Loss: 0.057 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.378 s\n",
            "Batch: 90 || Train Loss: 0.08 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.416 s\n",
            "Batch: 100 || Train Loss: 0.083 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.457 s\n",
            "Batch: 110 || Train Loss: 0.043 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.492 s\n",
            "Batch: 120 || Train Loss: 0.053 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.527 s\n",
            "Batch: 130 || Train Loss: 0.012 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.567 s\n",
            "Batch: 140 || Train Loss: 0.032 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.602 s\n",
            "Batch: 150 || Train Loss: 0.045 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.637 s\n",
            "Batch: 160 || Train Loss: 0.052 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.67 s\n",
            "Batch: 170 || Train Loss: 0.011 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.703 s\n",
            "Batch: 180 || Train Loss: 0.113 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.738 s\n",
            "Batch: 190 || Train Loss: 0.03 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.776 s\n",
            "Batch: 200 || Train Loss: 0.023 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.81 s\n",
            "Batch: 210 || Train Loss: 0.058 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.843 s\n",
            "Batch: 220 || Train Loss: 0.116 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.877 s\n",
            "Batch: 230 || Train Loss: 0.068 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.91 s\n",
            "Batch: 240 || Train Loss: 0.029 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.944 s\n",
            "Batch: 250 || Train Loss: 0.033 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 28.977 s\n",
            "Batch: 260 || Train Loss: 0.156 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.025 s\n",
            "Batch: 270 || Train Loss: 0.045 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.064 s\n",
            "Batch: 280 || Train Loss: 0.084 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.1 s\n",
            "Batch: 290 || Train Loss: 0.146 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.136 s\n",
            "Batch: 300 || Train Loss: 0.021 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.171 s\n",
            "Batch: 310 || Train Loss: 0.034 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.205 s\n",
            "Batch: 320 || Train Loss: 0.054 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.247 s\n",
            "Batch: 330 || Train Loss: 0.069 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.284 s\n",
            "Batch: 340 || Train Loss: 0.071 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.319 s\n",
            "Batch: 350 || Train Loss: 0.161 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.355 s\n",
            "Batch: 360 || Train Loss: 0.033 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.39 s\n",
            "Batch: 370 || Train Loss: 0.107 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.426 s\n",
            "Batch: 380 || Train Loss: 0.124 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.465 s\n",
            "Batch: 390 || Train Loss: 0.035 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.501 s\n",
            "Batch: 400 || Train Loss: 0.106 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.535 s\n",
            "Batch: 410 || Train Loss: 0.166 || Train Acc: [0.8758212560386475, 0.9336231884057972, 0.9446352657004831, 0.9496884057971015, 0.9533768115942028, 0.955355072463768, 0.9576956521739131, 0.9594975845410627, 0.9617608695652173, 0.9633019323671497, 0.9640024154589372, 0.9665845410628019, 0.9652415458937197, 0.9677487922705312, 0.9677777777777777, 0.9701207729468597, 0.9705821256038647, 0.9719299516908212, 0.9728913043478259] || Time: 29.57 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmUb8zsj4jF-",
        "outputId": "e7298ecd-cac7-4438-a230-3ca714ef33a9"
      },
      "source": [
        "a, o = train_batch.values()\r\n",
        "a"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}
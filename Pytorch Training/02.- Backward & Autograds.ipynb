{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograds\n",
    "\n",
    "Cada tensor tiene un parámetro booleano ```requires_grad``` que nos permitirá excluir o incluir la construcción de gráficos de dependencia para hacer el seguimiento de las gradientes de nuestro algoritmos.  Si alguno de los tensores necesita ser diferenciado, entonces tendremos que activar este parámetro antes. El poder activar y desactivar gradientes en ciertos tensores nos permite \"congelar\" ciertos layers en las redes neuronales, para poder re-entrenar un modelo (fine-tuning).\n",
    "\n",
    "Tal como se mencionó antes, nos sirve para crear gráficos de dependecia pero ¿Por qué esto es necesario? Cuando hacemos la optimización de nuestro algoritmo descenso de la gradiente, es necesario **tener un registro de las gradientes**, es decir, hacer un seguimiento de los errores a través de la red.\n",
    "\n",
    "Entonces, recordemos que en una red neuronal pasan dos cosas: \n",
    "\n",
    "- Forward Propagation: La red neuronal hace su mejor predicción y pasa todos los datos del input a través de las neuronas y capas que contenga con el fin de hacer su mejor predicción.\n",
    "\n",
    "- Backward Propagation: La red neuronal propaga el error a través de las derivadas y debe de tener una colección de ellas (date cuenta en este caso es necesita el ``requires_grad`` activo) optimizando los parámetros usando el descenso de la gradiente. En este sentido, torch.autograd es una herramienta para computar vectorialmente una matriz producto Jacobiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([2.,3.], requires_grad = True) \n",
    "b = torch.tensor([6.,4.], requires_grad = True)\n",
    "\n",
    "Q = 3*a**3 - b**2 #Asumiendo que a y b son parámetros de una red neuronal\n",
    "\n",
    "#donde dQ/da = [36,81] y dQ/db = [-12,-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Vector tensor([-12.,  65.], grad_fn=<SubBackward0>)\n",
      "a.grad= None\n",
      "b.grad= None\n"
     ]
    }
   ],
   "source": [
    "print('Q-Vector', Q)\n",
    "print('a.grad=',a.grad)\n",
    "print('b.grad=',b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada vez que llamamos ```.backward()``` derivamos nuestra función con respecto a todos los vectores implicados que tengan el ```requires_grad``` activo. Esto nos sirve principalmente para poder hacer luego el seguimiento de estas gradientes junto con el optimizador. Las gradientes se van a almacenar en ```tensor.grad``` donde tensor es el nombre del tensor. El optimizador llamará a estos vectores almacenados y hará su cálculo a través de ellos. Nota que por eso mismo podremos hacer el seguimiento de los parámetros. En este caso no tenemos optimizador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_gradiente_inicial = torch.tensor([1.,1.]) #Inicializo mi vector de gradientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos las gradientes y las almacenamos en los vectores activos.\n",
    "Q.backward(gradient=vector_gradiente_inicial) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Vector tensor([-12.,  65.], grad_fn=<SubBackward0>)\n",
      "a.grad= tensor([36., 81.])\n",
      "b.grad= tensor([-12.,  -8.])\n"
     ]
    }
   ],
   "source": [
    "print('Q-Vector', Q)\n",
    "print('a.grad=',a.grad) #La derivada o \"gradiente\" de Q con respecto a a\n",
    "print('b.grad=',b.grad) #dQ/da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actualizando los parámetros como en una red neuronal:\n",
    "\n",
    "Hasta este punto tenemos una forma de cómo almacenar las gradientes según una función. Pero cómo esto nos va a ser útil para **actualizar los parámetros**. Supongamos que tenemos una función ```Y = W*x + b``` donde ``W`` son los pesos a actualizar, ``X`` son los inputs y ``b`` es el bias o la constante de la ecuacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn(10,1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "x = torch.rand(1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nos toca formalizar la función ```Y = W*x + b``` recodermos acá que mientras los tensores W y b tengan el parámetro ``requires_grad`` activado, también lo tendrá la formalización de Y. Esto lo vemos si esque invocamos a Y y vemos que tiene asociada la función ``<AddBackward0>`` asociada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4971]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.matmul(x, W) + b\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos una función de pérdida para poder optimizar sobre. Digamos que esta función está dada por ```loss_function = (1 - Y)/2 ``` Esto nos servirá para poder calcular las gradientes de la función de pérdida con respecto a Y, es decir: dloss/dY. Que esto terminará dándonos la pérdida con respecto a Y y con respecto a W, según la regla de la cadena. Así, indirectamente tendremos qué W's de Y contribuyen más a la función de pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (1 - Y)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos las gradientes de loss con respecto a Y.\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dloss/W tensor([[-0.3478],\n",
      "        [-0.2626],\n",
      "        [-0.2391],\n",
      "        [-0.1834],\n",
      "        [-0.2414],\n",
      "        [-0.1846],\n",
      "        [-0.1108],\n",
      "        [-0.0056],\n",
      "        [-0.1630],\n",
      "        [-0.4082]])\n",
      "Dloss/b tensor([[-0.3478],\n",
      "        [-0.2626],\n",
      "        [-0.2391],\n",
      "        [-0.1834],\n",
      "        [-0.2414],\n",
      "        [-0.1846],\n",
      "        [-0.1108],\n",
      "        [-0.0056],\n",
      "        [-0.1630],\n",
      "        [-0.4082]])\n",
      "W tensor([[ 0.5150],\n",
      "        [-1.1924],\n",
      "        [-1.7766],\n",
      "        [ 1.8514],\n",
      "        [-0.4424],\n",
      "        [-0.3146],\n",
      "        [ 1.1133],\n",
      "        [-2.6996],\n",
      "        [-0.2121],\n",
      "        [ 1.0215]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('Dloss/W', W.grad)\n",
    "print('Dloss/b', W.grad)\n",
    "print('W', W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos las gradientes almacenadas, procedemos a **desactivarlas temporalmente** para poder actualizarlas y luego limpiar la \"caché\" de gradientes puesto que ya no nos sirven las antiguas. Esto lo hacemos con ```torch.no_grad()``` y usualmente se hace en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5150],\n",
       "        [-1.1924],\n",
       "        [-1.7766],\n",
       "        [ 1.8514],\n",
       "        [-0.4424],\n",
       "        [-0.3146],\n",
       "        [ 1.1133],\n",
       "        [-2.6996],\n",
       "        [-0.2121],\n",
       "        [ 1.0215]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W #Tenemos los Weights iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5497],\n",
       "        [-1.1662],\n",
       "        [-1.7527],\n",
       "        [ 1.8697],\n",
       "        [-0.4183],\n",
       "        [-0.2961],\n",
       "        [ 1.1244],\n",
       "        [-2.6991],\n",
       "        [-0.1958],\n",
       "        [ 1.0623]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad(): #Desactivamos las gradientes\n",
    "    W = W - 0.1 * W.grad\n",
    "\n",
    "W #Los weights finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RE-ESTRUCTURAR!\n",
    "#### ¿Cómo usar estos conceptos para re-entrenar un modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp_mnist_model import MLP #Es necesario tener la estructura del algoritmo en un archivo aparte.\n",
    "\n",
    "#Cargamos nuestro modelo\n",
    "model = torch.load('mnist_model.pt')\n",
    "\n",
    "#Cargamos datos generados de manera aleatoria (Solo para actualizar los parámetros)\n",
    "data = torch.rand(64, 784) #Tendré 64 muestras de un tensor de 784 (lo q acepta mi red)\n",
    "labels = torch.rand(64, 10) #Los labels con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La estructura del modelo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos ver los parámetros del modelo (Los weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecimos para ver qué tanto nuestro algoritmo clasifica el ruido\n",
    "output = model(data)\n",
    "pred = torch.argmax(output, dim=1)\n",
    "\n",
    "#Vamos a definir la pérdida (loss) de la sgte manera\n",
    "loss = (output - labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos un optimizador\n",
    "optim = torch.optim.SGD(model.parameters(), lr= 1e-2, momentum= 0.9)\n",
    "#Inicializamos el descenso de la gradiente\n",
    "optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El orden es opt.zero_grad(), loss.backward(), opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
